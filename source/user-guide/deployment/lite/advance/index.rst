.. _lite_advance:

=================================
使用 MegEngine Lite 部署模型进阶
=================================

MegEngine Lite 功能
-----------------------------

MegEngine 的 Inference 是经过长期工业界进行打磨，支持了大量的项目落地沉淀下来的一套功能强大，运行高效，内存友好的推理引擎，在 MegEngine Lite 对 MegEngine 的
Inference 接口进行了一层封装，对用户提供更加友好的接口，目前大概将 MegEngine Lite 的功能分为以下几类：

* 性能优化
* 内存优化
* 二进制库大小优化
* 跨设备模型运行
* 模型打包加密功能

文档目录
-----------

.. toctree::
   :maxdepth: 1

   performance-optimize/index
   memory-optimize
   binary-optimize
   pack-lite-model
   cv-examples
