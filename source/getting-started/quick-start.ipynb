{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "annual-hughes",
   "metadata": {},
   "source": [
    "# MegEngine 10 分钟快速上手"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-legislature",
   "metadata": {},
   "source": [
    "| ![](../_static/logo/megvii-32.svg) [在 MegStudio 运行](https://studio.brainpp.com/project/5424) | ![](../_static/logo/github-32.svg) [查看源文件](https://github.com/MegEngine/Documentation/blob/main/source/getting-started/quick-start.ipynb) |\n",
    "| --- | --- |\n",
    "\n",
    "本教程假定你具备一定的 Python 编程基础，并了解深度学习的基础概念。\n",
    "\n",
    "我们将向你介绍使用 MegEngine 实现的完整的机器学习工作流程，以便你快速地熟悉 MegEngine 常见 [Python API](https://megengine.org.cn/doc/stable/zh/reference/index.html) 的使用方式。\n",
    "\n",
    "请先运行下面的代码，检验你的环境中是否已经安装好 MegEngine（[安装教程](https://megengine.org.cn/doc/stable/zh/user-guide/install/)）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "later-ability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import megengine\n",
    "\n",
    "print(megengine.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-sierra",
   "metadata": {},
   "source": [
    "接下来我们将通过 MNIST 手写数字识别的案例帮助你快速上手 MegEngine 的使用。\n",
    "\n",
    "## 数据的加载和预处理\n",
    "\n",
    "数据的加载和预处理往往会耗费大量的精力， MegEngine 提供了一系列接口来规范化这些处理工作：\n",
    "\n",
    "- [megengine.data.dataset.Dataset](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.data.dataset.Dataset.html) 是 MegEngine 中表示数据集的抽象类，存储样本和相应的标签；\n",
    "- [megengine.data.DataLoader](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.data.DataLoader.html) 负责根据传入的 `Dataset` 等参数生成一个可迭代的对象。\n",
    "\n",
    "在 [megengine.data.dataset](https://megengine.org.cn/doc/stable/zh/reference/data.html#dataset) 模块中为用户提供了非常多经典的数据集，比如本次教程中用到的 [MNIST](http://yann.lecun.com/exdb/mnist/) 数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "common-vegetation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m15 10:44:42 \u001b[0mprocess the raw files of train set...\n",
      "100%|██████████████████████████████████| 60000/60000 [00:02<00:00, 29190.52it/s]\n",
      "100%|████████████████████████████████| 60000/60000 [00:00<00:00, 1284881.83it/s]\n",
      "\u001b[32m15 10:44:45 \u001b[0mprocess the raw files of test set...\n",
      "100%|██████████████████████████████████| 10000/10000 [00:00<00:00, 29087.64it/s]\n",
      "100%|████████████████████████████████| 10000/10000 [00:00<00:00, 1359932.56it/s]\n"
     ]
    }
   ],
   "source": [
    "from megengine.data.dataset import MNIST\n",
    "\n",
    "# 如果使用 MegStudio 环境，请将 MNIST_DATA_PATH 为 /home/megstudio/dataset/MNIST/\n",
    "MNIST_DATA_PATH = \"/data/datasets/MNIST/\"\n",
    "\n",
    "# 获取训练数据集，如果本地没有数据集，请将 download 参数设置为 True\n",
    "train_dataset = MNIST(root=MNIST_DATA_PATH, train=True, download=False)\n",
    "test_dataset = MNIST(root=MNIST_DATA_PATH, train=False, download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-century",
   "metadata": {},
   "source": [
    "对于如何加载自定义的 `Dataset` ，请参考用户指南 [使用 Data 处理 I/O 与数据集](https://megengine.org.cn/doc/stable/zh/user-guide/model-development/data/index.html) 。\n",
    "\n",
    "将 `Dataset` 作为参数传给 `DataLoader` 时，我们还需要为其指定数据预处理和抽样逻辑：\n",
    "\n",
    "- [megengine.data.transfrom](https://megengine.org.cn/doc/stable/zh/reference/data.html#transform) 提供了常见的数据变换操作，作为预处理手段，支持 `Compose` 组合；\n",
    "- [megengine.data.sampler](https://megengine.org.cn/doc/stable/zh/reference/data.html#sampler) 提供了常见的采样方法，如顺序采样和随机采样等，可指定 ``batch_size`` 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "major-headline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megengine.data import DataLoader\n",
    "from megengine.data.transform import ToMode, Pad, Normalize, Compose\n",
    "from megengine.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "# 创建 Sampler\n",
    "train_sampler = RandomSampler(train_dataset, batch_size=batch_size)\n",
    "test_sampler = SequentialSampler(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 数据预处理方式\n",
    "transform = Compose([\n",
    "    Normalize(mean=0.1307*255, std=0.3081*255),\n",
    "    Pad(2),\n",
    "    ToMode('CHW'),\n",
    "])\n",
    "\n",
    "# 创建 Dataloader\n",
    "train_dataloader = DataLoader(train_dataset, train_sampler, transform)\n",
    "test_dataloader  = DataLoader(test_dataset, test_sampler, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "consolidated-bracelet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  (64, 1, 32, 32)\n",
      "Shape of y:  (64,) int32\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(\"Shape of X: \", X.shape) # [N, C, H, W]\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-secret",
   "metadata": {},
   "source": [
    "## 定义网络结构\n",
    "\n",
    "在 MegEngine 中定义网络最常见的方式是创建一个继承自 [megengine.module.Module](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.module.Module.html) 的类，接着：\n",
    "\n",
    "- 在 `__init__` 中定义网络的层，各类算子可以在 [functional](https://megengine.org.cn/doc/stable/zh/reference/functional.html) 和 [module](https://megengine.org.cn/doc/stable/zh/reference/module.html) 模块中找到；\n",
    "- 通过 `forward` 方法描述数据通过网络前向传播时依次执行的算子，从而就定义了网络的结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thick-tonight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (classifier): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import megengine.module as M\n",
    "import megengine.functional as F\n",
    "\n",
    "# 定义网络，以经典的 LeNet 结构为例（但激活函数选用 ReLU）\n",
    "class LeNet(M.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 单信道图片, 两层  5x5 卷积 + ReLU + 池化\n",
    "        self.conv1 = M.Conv2d(1, 6, 5)\n",
    "        self.relu1 = M.ReLU()\n",
    "        self.pool1 = M.MaxPool2d(2, 2)\n",
    "        self.conv2 = M.Conv2d(6, 16, 5)\n",
    "        self.relu2 = M.ReLU()\n",
    "        self.pool2 = M.MaxPool2d(2, 2)\n",
    "        # 两层全连接 + ReLU\n",
    "        self.fc1 = M.Linear(16 * 5 * 5, 120)\n",
    "        self.relu3 = M.ReLU()\n",
    "        self.fc2 = M.Linear(120, 84)\n",
    "        self.relu4 = M.ReLU()\n",
    "        # 分类器\n",
    "        self.classifier = M.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        # F.flatten 将原本形状为 (N, C, H, W) 的张量 x 从第一个维度（即 C）开始拉平成一个维度，\n",
    "        # 得到的新张量形状为 (N, C*H*W) 。 等价于 reshape 操作： x = x.reshape(x.shape[0], -1)\n",
    "        x = F.flatten(x, 1)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "# 实例化网络\n",
    "net = LeNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-plate",
   "metadata": {},
   "source": [
    "## 定义损失函数、优化器\n",
    "\n",
    "为了实现对模型的训练（即对模型中参数的优化），我们还需要定义：\n",
    "\n",
    "- 损失函数（Loss Function），大部分常见的损失函数实现在 [megengine.function.loss](https://megengine.org.cn/doc/stable/zh/reference/functional.html#loss) 模块中；\n",
    "- 优化器（Optimizer），常见的优化器实现在 [megengine.optimizer](https://megengine.org.cn/doc/stable/zh/reference/optimizer.html), 且支持不同的优化策略；\n",
    "- MegEngine 的自动求导功能由 [megengine.autodiff](https://megengine.org.cn/doc/stable/zh/reference/autodiff.html) 模块实现，其中 [GradManager](https://megengine.org.cn/doc/stable/zh/reference/autodiff.html#gradmanager) 负责管理梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "crazy-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megengine.optimizer import SGD\n",
    "from megengine.autodiff import GradManager\n",
    "\n",
    "optimizer = SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "gm = GradManager().attach(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-constitution",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "MegEngine 中的计算默认以张量（[Tensor](https://megengine.org.cn/doc/stable/zh/reference/tensor.html)）作为基础数据结构，因此记得将我们输入的数据转化为 Tensor.\n",
    "\n",
    "- 当检测到 GPU 环境时，MegEngine 会自动将相应的计算过程在 GPU 中执行 **（无需手动指定设备）** 从而实现加速。\n",
    "- 如果需要查询 Tensor 所在设备，可以使用 [Tensor.device](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.Tensor.device.html) ; \n",
    "- 如果需要改变 Tensor 所在设备，可以使用 [Tensor.to](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.Tensor.to.html) 或 [functional.copy](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.functional.copy.html) .\n",
    "\n",
    "我们设置 10 个训练周期，整个过程中将对训练数据集分批次进行预测，根据反向传播算法更新模型的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "developing-biodiversity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss 0.002867442769991855\n",
      "epoch: 1, loss 0.0009182994486764074\n",
      "epoch: 2, loss 0.0006611305125678578\n",
      "epoch: 3, loss 0.0005199052049467961\n",
      "epoch: 4, loss 0.00046812092686692873\n",
      "epoch: 5, loss 0.000387949584890157\n",
      "epoch: 6, loss 0.0003237317308783531\n",
      "epoch: 7, loss 0.00028708203192800286\n",
      "epoch: 8, loss 0.00025323729968319337\n",
      "epoch: 9, loss 0.0002447911872838934\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import megengine as mge\n",
    "\n",
    "net.train()\n",
    "total_epochs = 10\n",
    "for epoch in range(total_epochs):\n",
    "    total_loss = 0\n",
    "    for step, (batch_data, batch_label) in enumerate(train_dataloader):\n",
    "        batch_data = mge.tensor(batch_data)\n",
    "        batch_label = mge.tensor(batch_label).astype(np.int32)\n",
    "        \n",
    "        with gm:\n",
    "            pred = net(batch_data)\n",
    "            loss = F.loss.cross_entropy(pred, batch_label)\n",
    "            gm.backward(loss)\n",
    "            optimizer.step().clear_grad()\n",
    "        \n",
    "        total_loss += loss.numpy().item()\n",
    "    print(\"epoch: {}, loss {}\".format(epoch, total_loss/len(train_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-textbook",
   "metadata": {},
   "source": [
    "## 模型的保存与加载\n",
    "\n",
    "在 MegEngine 中通过使用 [megengine.save](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.save.html) 和 [megengine.load](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.load.html) 进行模型的保存与加载。\n",
    "\n",
    "我们首先将训练好的模型的保存到本地："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interim-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "mge.save(net.state_dict(), 'mnist_net.mge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-background",
   "metadata": {},
   "source": [
    "接着我们可以加载本地的模型文件，在测试集上进行预测，以检测模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extraordinary-priest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 9900, total: 10000, accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "net = LeNet()\n",
    "state_dict = mge.load('mnist_net.mge')\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for idx, (batch_data, batch_label) in enumerate(test_dataloader):\n",
    "    batch_data = mge.tensor(batch_data)\n",
    "    batch_label = mge.tensor(batch_label).astype(np.int32)\n",
    "    \n",
    "    pred = net(batch_data)\n",
    "    loss = F.loss.cross_entropy(pred, batch_label)\n",
    "    predicted = pred.numpy().argmax(axis=1)\n",
    "    correct += (predicted == batch_label.numpy()).sum().item()\n",
    "    total += batch_label.shape[0]\n",
    "print(\"correct: {}, total: {}, accuracy: {}\".format(correct, total, float(correct) / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
