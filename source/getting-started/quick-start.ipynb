{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "occupied-substitute",
   "metadata": {},
   "source": [
    "# 天元 MegEngine 快速上手\n",
    "\n",
    "注意：本教程假定你具备一定的 Python 编程基础，并了解深度学习的基础概念。\n",
    "\n",
    "我们将向你介绍使用天元 MegEngine 实现的完整的机器学习工作流程，以便你快速地熟悉常见 API 的使用方式。\n",
    "\n",
    "请先运行下面的代码，检验你的环境中是否已经安装好 MegEngine（[访问官网安装教程](https://megengine.org.cn/install/)）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acute-round",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "import megengine\n",
    "\n",
    "print(megengine.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quality-ground",
   "metadata": {},
   "source": [
    "接下来我们将通过 MNIST 手写数字识别的案例帮助你快速上手天元 MegEngine 的使用。\n",
    "\n",
    "## 数据的加载和预处理\n",
    "\n",
    "数据的加载和预处理往往会耗费大量的精力， MegEngine 提供了一系列接口来规范化这些处理工作：\n",
    "\n",
    "- [megengine.data.dataset.Dataset](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.data.dataset.Dataset.html) 是 MegEngine 中表示数据集的抽象类，存储样本和相应的标签；\n",
    "- [megengine.data.DataLoader](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.data.DataLoader.html) 负责根据传入的 `Dataset` 等参数生成一个可迭代的对象。\n",
    "\n",
    "在 [megengine.data.dataset](https://megengine.org.cn/doc/stable/zh/reference/data.html#dataset) 模块中为用户提供了非常多经典的数据集，比如本次教程中用到的 [MNIST](http://yann.lecun.com/exdb/mnist/) 数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "minute-seating",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m02 01:49:55 \u001b[0mprocess the raw files of train set...\n",
      "100%|██████████████████████████████████| 60000/60000 [00:01<00:00, 34044.69it/s]\n",
      "100%|████████████████████████████████| 60000/60000 [00:00<00:00, 1738115.31it/s]\n",
      "\u001b[32m02 01:49:57 \u001b[0mprocess the raw files of test set...\n",
      "100%|██████████████████████████████████| 10000/10000 [00:00<00:00, 33288.44it/s]\n",
      "100%|████████████████████████████████| 10000/10000 [00:00<00:00, 1693641.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from megengine.data.dataset import MNIST\n",
    "\n",
    "# 如果使用 MegStudio 环境，请将 MNIST_DATA_PATH 为 /home/megstudio/dataset/MNIST/\n",
    "MNIST_DATA_PATH = \"/data/datasets/MNIST/\"\n",
    "\n",
    "# 获取训练数据集，如果本地没有数据集，请将 download 参数设置为 True\n",
    "train_dataset = MNIST(root=MNIST_DATA_PATH, train=True, download=False)\n",
    "test_dataset = MNIST(root=MNIST_DATA_PATH, train=False, download=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-bibliography",
   "metadata": {},
   "source": [
    "对于如何加载自定义的 `Dataset` ，请参考用户指南 利用 Dataset 封装一个数据集。\n",
    "\n",
    "将 `Dataset` 作为参数传给 `DataLoader` 时，我们还需要为其指定数据预处理和抽样逻辑：\n",
    "\n",
    "- [megengine.data.transfrom](https://megengine.org.cn/doc/stable/zh/reference/data.html#transform) 提供了常见的数据变换操作，作为预处理手段，支持 `Compose` 组合；\n",
    "- [megengine.data.sampler](https://megengine.org.cn/doc/stable/zh/reference/data.html#sampler) 提供了常见的采样方法，如顺序采样和随机采样等，可指定 ``batch_size`` 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "shaped-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megengine.data import DataLoader\n",
    "from megengine.data.transform import ToMode, Pad, Normalize, Compose\n",
    "from megengine.data.sampler import RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size=64\n",
    "\n",
    "# 创建 Sampler\n",
    "train_sampler = RandomSampler(train_dataset, batch_size=batch_size)\n",
    "test_sampler = SequentialSampler(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# 数据预处理方式\n",
    "transform = Compose([\n",
    "    Normalize(mean=0.1307*255, std=0.3081*255),\n",
    "    Pad(2),\n",
    "    ToMode('CHW'),\n",
    "])\n",
    "\n",
    "# 创建 Dataloader\n",
    "train_dataloader = DataLoader(train_dataset, train_sampler, transform)\n",
    "test_dataloader = dataloader_test = DataLoader(test_dataset, test_sampler, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "particular-birmingham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0\n",
      "Shape of X:  (64, 1, 32, 32)\n",
      "Shape of y:  (64,) int32\n"
     ]
    }
   ],
   "source": [
    "for idx, (X, y) in enumerate(test_dataloader):\n",
    "    print(\"Index: \", idx)\n",
    "    print(\"Shape of X: \", X.shape) # [N, C, H, W]\n",
    "    print(\"Shape of y: \", y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-kentucky",
   "metadata": {},
   "source": [
    "## 定义网络结构\n",
    "\n",
    "在 MegEngine 中定义网络最常见的方式是创建一个继承自 [megengine.module.Module](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.module.Module.html) 的类，接着：\n",
    "\n",
    "- 在 `__init__` 方法中定义网络的层，各类算子可以在 [megengine.functional](https://megengine.org.cn/doc/stable/zh/reference/functional.html) 和 [megengine.module](https://megengine.org.cn/doc/stable/zh/reference/module.html) 中找到；\n",
    "- 通过 `forward` 方法描述数据通过网络前向传播时依次执行的算子，这些算子和它们之间的依赖关系也就定义了网络的结构。\n",
    "\n",
    "当检测到 GPU 环境时，MegEngine 会自动将相应的计算过程在 GPU 中执行（无需手动指定设备）从而实现加速。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continental-science",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv0): Conv2d(1, 20, kernel_size=(5, 5), bias=False)\n",
      "  (bn0): BatchNorm2d(20, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "  (relu0): ReLU()\n",
      "  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv1): Conv2d(20, 20, kernel_size=(5, 5), bias=False)\n",
      "  (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (fc0): Linear(in_features=500, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import megengine.module as M\n",
    "import megengine.functional as F\n",
    "\n",
    "# 定义网络\n",
    "class Net(M.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = M.Conv2d(1, 20, kernel_size=5, bias=False)\n",
    "        self.bn0 = M.BatchNorm2d(20)\n",
    "        self.relu0 = M.ReLU()\n",
    "        self.pool0 = M.MaxPool2d(2)\n",
    "        self.conv1 = M.Conv2d(20, 20, kernel_size=5, bias=False)\n",
    "        self.bn1 = M.BatchNorm2d(20)\n",
    "        self.relu1 = M.ReLU()\n",
    "        self.pool1 = M.MaxPool2d(2)\n",
    "        self.fc0 = M.Linear(500, 64, bias=True)\n",
    "        self.relu2 = M.ReLU()\n",
    "        self.fc1 = M.Linear(64, 10, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.bn0(x)\n",
    "        x = self.relu0(x)\n",
    "        x = self.pool0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = F.flatten(x, 1)\n",
    "        x = self.fc0(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "# 实例化网络\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-blond",
   "metadata": {},
   "source": [
    "## 定义损失函数、优化器\n",
    "\n",
    "为了实现对模型的训练（即对模型中参数的优化），我们还需要定义：\n",
    "\n",
    "- 损失函数（Loss Function），大部分常见的损失函数实现在 [megengine.function.loss](https://megengine.org.cn/doc/stable/zh/reference/functional.html#loss) 模块中；\n",
    "- 优化器（Optimizer），常见的优化器实现在 [megengine.optimizer](https://megengine.org.cn/doc/stable/zh/reference/optimizer.html), 支持不同的学习率、权重衰减等等优化策略；\n",
    "- MegEngine 的自动求导功能由 [megengine.autodiff](https://megengine.org.cn/doc/stable/zh/reference/autodiff.html) 模块实现，其中 [GradManager](https://megengine.org.cn/doc/stable/zh/reference/autodiff.html#gradmanager) 负责管理梯度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forced-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megengine.optimizer import SGD\n",
    "from megengine.autodiff import GradManager\n",
    "\n",
    "optimizer = SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "gm = GradManager().attach(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-trademark",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "\n",
    "在 MegEngine 中计算图默认为动态图模式，可通过 [megengine.jit.trace](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.jit.trace.html) 非常便捷地将动态图转为静态图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fatty-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "from megengine.jit import trace\n",
    "\n",
    "@trace(symbolic=True)\n",
    "def train_func(data, label, *, gm, net):\n",
    "    net.train()\n",
    "    with gm:\n",
    "        pred = net(data)\n",
    "        loss = F.loss.cross_entropy(pred, label)\n",
    "        gm.backward(loss)\n",
    "    return pred, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-posting",
   "metadata": {},
   "source": [
    "我们设置 10 个训练周期，整个过程中将对训练数据集分批次进行预测，根据反向传播算法更新模型的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caring-inspector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss 0.13873870883669173\n",
      "epoch: 1, loss 0.05043510790826924\n",
      "epoch: 2, loss 0.03717820324114899\n",
      "epoch: 3, loss 0.029249643720289282\n",
      "epoch: 4, loss 0.025445997079552363\n",
      "epoch: 5, loss 0.02158043481139486\n",
      "epoch: 6, loss 0.018581382247176505\n",
      "epoch: 7, loss 0.01729959516382929\n",
      "epoch: 8, loss 0.015273293452476388\n",
      "epoch: 9, loss 0.014109803669488252\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import megengine as mge\n",
    "\n",
    "total_epochs = 10\n",
    "for epoch in range(total_epochs):\n",
    "    total_loss = 0\n",
    "    for step, (batch_data, batch_label) in enumerate(train_dataloader):\n",
    "        batch_label = batch_label.astype(np.int32)\n",
    "        pred, loss = train_func(mge.tensor(batch_data), mge.tensor(batch_label), gm=gm, net=net)\n",
    "        optimizer.step().clear_grad()\n",
    "        total_loss += loss.numpy().item()\n",
    "    print(\"epoch: {}, loss {}\".format(epoch, total_loss/len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-lawsuit",
   "metadata": {},
   "source": [
    "## 模型的保存与加载\n",
    "\n",
    "在 MegEngine 中通过使用 [megengine.save](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.save.html) 和 [megengine.load](https://megengine.org.cn/doc/stable/zh/reference/api/megengine.load.html) 进行模型的保存与加载。\n",
    "\n",
    "我们首先将训练好的模型的保存到本地："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "forward-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "mge.save(net.state_dict(), 'mnist_net.mge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-child",
   "metadata": {},
   "source": [
    "接着我们可以加载本地的模型文件，在测试集上进行预测，以检测模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "administrative-wales",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 9919, total: 10000, accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "state_dict = mge.load('mnist_net.mge')\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "# 在测试集上验证模型性能，注意此时要使用 .eval()\n",
    "@trace(symbolic=True)\n",
    "def eval_func(data, label, *, net):\n",
    "    net.eval()\n",
    "    pred = net(data)\n",
    "    loss = F.loss.cross_entropy(pred, label)\n",
    "    return pred, loss\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for idx, (batch_data, batch_label) in enumerate(test_dataloader):\n",
    "    batch_label = batch_label.astype(np.int32)\n",
    "    pred, loss = eval_func(mge.tensor(batch_data), mge.tensor(batch_label), net=net)\n",
    "    predicted = pred.numpy().argmax(axis=1)\n",
    "    correct += (predicted == batch_label).sum().item()\n",
    "    total += batch_label.shape[0]\n",
    "print(\"correct: {}, total: {}, accuracy: {}\".format(correct, total, float(correct) / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
