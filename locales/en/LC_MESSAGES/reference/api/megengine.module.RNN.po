
msgid ""
msgstr ""
"Project-Id-Version:  megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-09-21 10:50+0000\n"
"PO-Revision-Date: 2023-04-21 09:27+0000\n"
"Last-Translator: \n"
"Language: en_US\n"
"Language-Team: English\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../source/reference/api/megengine.module.RNN.rst:5
msgid "RNN"
msgstr ""

#: megengine.module.rnn.RNN:1 of
msgid ""
"Applies a multi-layer Elman RNN with :math:`\\tanh` or "
":math:`\\text{ReLU}` non-linearity to an input sequence."
msgstr ""

#: megengine.module.rnn.RNN:5 of
msgid ""
"For each element in the input sequence, each layer computes the following"
" function:"
msgstr ""

#: megengine.module.rnn.RNN:7 of
msgid ""
"h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n"
"\n"
msgstr ""

#: megengine.module.rnn.RNN:10 of
msgid ""
"where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the "
"input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the "
"previous layer at time `t-1` or the initial hidden state at time `0`. If "
":attr:`nonlinearity` is ``'relu'``, then :math:`\\text{ReLU}` is used "
"instead of :math:`\\tanh`."
msgstr ""

#: megengine.module.rnn.RNN of
msgid "参数"
msgstr ""

#: megengine.module.rnn.RNN:15 of
msgid "The number of expected features in the input `x`."
msgstr ""

#: megengine.module.rnn.RNN:17 of
msgid "The number of features in the hidden state `h`."
msgstr ""

#: megengine.module.rnn.RNN:19 of
msgid ""
"Number of recurrent layers. E.g., setting ``num_layers=2`` would mean "
"stacking two RNNs together to form a `stacked RNN`, with the second RNN "
"taking in outputs of the first RNN and computing the final results. "
"Default: 1."
msgstr ""

#: megengine.module.rnn.RNN:24 of
msgid ""
"The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. "
"Default: ``'tanh'``."
msgstr ""

#: megengine.module.rnn.RNN:26 of
msgid ""
"If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`."
" Default: ``True``."
msgstr ""

#: megengine.module.rnn.RNN:29 of
msgid ""
"If ``True``, then the input and output tensors are provided as `(batch, "
"seq, feature)` instead of `(seq, batch, feature)`. Note that this does "
"not apply to hidden or cell states. See the Inputs/Outputs sections below"
" for details.  Default: ``False``."
msgstr ""

#: megengine.module.rnn.RNN:34 of
msgid ""
"If non-zero, introduces a `Dropout` layer on the outputs of each RNN "
"layer except the last layer, with dropout probability equal to "
":attr:`dropout`. Default: 0."
msgstr ""

#: megengine.module.rnn.RNN:38 of
msgid "If ``True``, becomes a bidirectional RNN. Default: ``False``."
msgstr ""

#: megengine.module.rnn.RNN:63 of
msgid "Shape:"
msgstr ""

#: megengine.module.rnn.RNN:57 of
msgid "Inputs: input, h_0"
msgstr ""

#: megengine.module.rnn.RNN:43 of
msgid ""
"input: :math:`(L, N, H_{in})` when ``batch_first=False`` or :math:`(N, L,"
" H_{in})`"
msgstr ""

#: megengine.module.rnn.RNN:44 of
msgid "when ``batch_first=True``. Containing the features of the input sequence."
msgstr ""

#: megengine.module.rnn.RNN:46 of
msgid ""
"h_0: :math:`(D * \\text{num\\_layers}, N, H_{out})`. Containing the "
"initial hidden"
msgstr ""

#: megengine.module.rnn.RNN:46 of
msgid "state for each element in the batch. Defaults to zeros if not provided."
msgstr ""

#: megengine.module.rnn.RNN:48 of
msgid "where:"
msgstr ""

#: megengine.module.rnn.RNN:50 of
msgid ""
"\\begin{aligned}\n"
"    N ={} & \\text{batch size} \\\\\n"
"    L ={} & \\text{sequence length} \\\\\n"
"    D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n"
"    H_{in} ={} & \\text{input\\_size} \\\\\n"
"    H_{out} ={} & \\text{hidden\\_size}\n"
"\\end{aligned}\n"
"\n"
msgstr ""

#: megengine.module.rnn.RNN:63 of
msgid "Outputs: output, h_n"
msgstr ""

#: megengine.module.rnn.RNN:60 of
msgid ""
"output: :math:`(L, N, D * H_{out})` when ``batch_first=False`` or "
":math:`(N, L, D * H_{out})` when ``batch_first=True``."
msgstr ""

#: megengine.module.rnn.RNN:61 of
msgid ""
"Containing the output features `(h_t)` from the last layer of the RNN, "
"for each `t`."
msgstr ""

#: megengine.module.rnn.RNN:62 of
msgid ""
"h_n: :math:`(D * \\text{num\\_layers}, N, H_{out})`. Containing the final"
" hidden state for each element in the batch."
msgstr ""

#: megengine.module.rnn.RNN:66 of
msgid "实际案例"
msgstr ""

#: megengine.module.rnn.RNN:79 of
msgid "Outputs:"
msgstr ""

#~ msgid "The number of expected features in the input `x`"
#~ msgstr ""

#~ msgid "The number of features in the hidden state `h`"
#~ msgstr ""

#~ msgid ""
#~ "Number of recurrent layers. E.g., "
#~ "setting ``num_layers=2`` would mean stacking"
#~ " two RNNs together to form a "
#~ "`stacked RNN`, with the second RNN "
#~ "taking in outputs of the first RNN"
#~ " and computing the final results. "
#~ "Default: 1"
#~ msgstr ""

#~ msgid ""
#~ "The non-linearity to use. Can be"
#~ " either ``'tanh'`` or ``'relu'``. Default:"
#~ " ``'tanh'``"
#~ msgstr ""

#~ msgid ""
#~ "If ``False``, then the layer does "
#~ "not use bias weights `b_ih` and "
#~ "`b_hh`. Default: ``True``"
#~ msgstr ""

#~ msgid ""
#~ "If ``True``, then the input and "
#~ "output tensors are provided as `(batch,"
#~ " seq, feature)` instead of `(seq, "
#~ "batch, feature)`. Note that this does"
#~ " not apply to hidden or cell "
#~ "states. See the Inputs/Outputs sections "
#~ "below for details.  Default: ``False``"
#~ msgstr ""

#~ msgid ""
#~ "If non-zero, introduces a `Dropout` "
#~ "layer on the outputs of each RNN"
#~ " layer except the last layer, with"
#~ " dropout probability equal to "
#~ ":attr:`dropout`. Default: 0"
#~ msgstr ""

#~ msgid "If ``True``, becomes a bidirectional RNN. Default: ``False``"
#~ msgstr ""

#~ msgid ""
#~ "**input**: tensor of shape :math:`(L, N,"
#~ " H_{in})` when ``batch_first=False`` or "
#~ ":math:`(N, L, H_{in})` when "
#~ "``batch_first=True`` containing the features "
#~ "of the input sequence.  The input "
#~ "can also be a packed variable "
#~ "length sequence. See "
#~ ":func:`torch.nn.utils.rnn.pack_padded_sequence` or "
#~ ":func:`torch.nn.utils.rnn.pack_sequence` for details."
#~ msgstr ""

#~ msgid ""
#~ "**h_0**: tensor of shape :math:`(D * "
#~ "\\text{num\\_layers}, N, H_{out})` containing "
#~ "the initial hidden state for each "
#~ "element in the batch. Defaults to "
#~ "zeros if not provided."
#~ msgstr ""

#~ msgid ""
#~ "**output**: tensor of shape :math:`(L, "
#~ "N, D * H_{out})` when "
#~ "``batch_first=False`` or :math:`(N, L, D "
#~ "* H_{out})` when ``batch_first=True`` "
#~ "containing the output features `(h_t)` "
#~ "from the last layer of the RNN,"
#~ " for each `t`. If a "
#~ ":class:`torch.nn.utils.rnn.PackedSequence` has been "
#~ "given as the input, the output "
#~ "will also be a packed sequence."
#~ msgstr ""

#~ msgid ""
#~ "**h_n**: tensor of shape :math:`(D * "
#~ "\\text{num\\_layers}, N, H_{out})` containing "
#~ "the final hidden state for each "
#~ "element in the batch."
#~ msgstr ""

