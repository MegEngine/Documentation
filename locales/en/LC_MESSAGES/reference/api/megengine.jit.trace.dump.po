msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-12-08 20:45+0800\n"
"PO-Revision-Date: 2021-12-13 14:29\n"
"Last-Translator: \n"
"Language: en_US\n"
"Language-Team: English\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: en\n"
"X-Crowdin-File: /[MegEngine.Documentation] main/locales/zh_CN/LC_MESSAGES/reference/api/megengine.jit.trace.dump.po\n"
"X-Crowdin-File-ID: 2352\n"

#: ../../source/reference/api/megengine.jit.trace.dump.rst:2
msgid "megengine.jit.trace.dump"
msgstr ""

#: megengine.jit.tracing.trace.dump:1 of
msgid "Serializes trace to file system."
msgstr ""

#: megengine.jit.tracing.trace.dump of
msgid "参数"
msgstr ""

#: megengine.jit.tracing.trace.dump:3 of
msgid "output file, could be file object or filename."
msgstr ""

#: megengine.jit.tracing.trace.dump:4 of
msgid "names of the input tensors in the traced function."
msgstr ""

#: megengine.jit.tracing.trace.dump:5 of
msgid "names of the output tensors in the traced function, use the default name if not specified."
msgstr ""

#: megengine.jit.tracing.trace.dump:7 of
msgid "whether output is appended to ``file``. Only works when ``file`` is str."
msgstr ""

#: megengine.jit.tracing.trace.dump:10 of
msgid "level for keeping variable names:  * 0: none of the names are kept * 1: (default)keep names of output vars * 2: keep names of all (output and internal) vars"
msgstr ""

#: megengine.jit.tracing.trace.dump:16 of
msgid "whether to keep operator names."
msgstr ""

#: megengine.jit.tracing.trace.dump:18 of
msgid "whether to keep param names, so param values can be easily manipulated after loading model"
msgstr ""

#: megengine.jit.tracing.trace.dump:21 of
msgid "whether to keep priority setting for operators"
msgstr ""

#: megengine.jit.tracing.trace.dump:22 of
msgid "a string for path or a file handler. if is not None, then the dump information for code strip would be written to ``strip_info_file``"
msgstr ""

#: megengine.jit.tracing.trace.dump:24 of
msgid "will be check when `strip_info_file` is not None. if set true, the information for code strip will be append to strip_info_file. if set false, will rewrite strip_info_file"
msgstr ""

#: megengine.jit.tracing.trace.dump:27 of
msgid "enbale optmizations, will skip all optimize options if this is False. Default: True"
msgstr ""

#: megengine.jit.tracing.trace.dump:30 of
msgid "any type object, which will be pickled to bytes."
msgstr ""

#: megengine.jit.tracing.trace.dump:32 of
msgid "whether to save metadata into output file."
msgstr ""

#: megengine.jit.tracing.trace.dump:33 of
msgid "input test data and current network output would be used as groundtruth. The format is \"var0:file0;var1:file1...\" to specify data files for input vars. It can also be \"#rand(min,max,shape...)\" for generating random input data, for example, \"#rand(0,255)\", \"#rand(0,255,1,3,224,224)\" or \"#rand(0, 255, 1, ...)\" where `...` means the remaining part of the original shape. If the shape is not specified, the shape of corresponding input tensors in the network will be used. If there is only one input var, its name can be omitted. Each data file can either be an image which can be loaded by opencv, or a pickled numpy.ndarray. This option can be given multiple times to add multiple testcases. If you start the data with the letter @, the rest should be a filename, and each line in the file should be a single datum in the format described above. *NOTE* If `input_data` is not None, you can only use load-and-run to run the output file."
msgstr ""

#: megengine.jit.tracing.trace.dump:45 of
msgid "how many times the input image is repeated. Useful when running benchmark for batch size other than one. Have no effect on randomly generated input data."
msgstr ""

#: megengine.jit.tracing.trace.dump:47 of
msgid "whether set verbose to False in assert_equal opr."
msgstr ""

#: megengine.jit.tracing.trace.dump:48 of
msgid "whether insert assert_equal opr to check result; this option is useful for benchmarking."
msgstr ""

#: megengine.jit.tracing.trace.dump:50 of
msgid "max error for assert_equal check during runtime."
msgstr ""

#: megengine.jit.tracing.trace.dump:51 of
msgid "whether resize input image to fit input var shape."
msgstr ""

#: megengine.jit.tracing.trace.dump:52 of
msgid "a python expression to transform the input data. Example: data / np.std(data)"
msgstr ""

#: megengine.jit.tracing.trace.dump:55 of
msgid "using different dump formats."
msgstr ""

#: megengine.jit.tracing.trace.dump:57 of
msgid "Keyword Arguments:"
msgstr ""

#: megengine.jit.tracing.trace.dump:59 of
msgid "enable_io16xc32 -- whether to use float16 for I/O between oprs and use float32 as internal computation precision. Note the output var would be changed to float16."
msgstr ""

#: megengine.jit.tracing.trace.dump:63 of
msgid "enable_ioc16 -- whether to use float16 for both I/O and computation precision."
msgstr ""

#: megengine.jit.tracing.trace.dump:66 of
msgid "enable_hwcd4 -- whether to use NHWCD4 data layout. This is faster on some OpenCL backend."
msgstr ""

#: megengine.jit.tracing.trace.dump:69 of
msgid "enable_nchw88 -- whether to use NCHW88 data layout, currently used in X86 AVX backend."
msgstr ""

#: megengine.jit.tracing.trace.dump:72 of
msgid "enable_nchw44 -- whether to use NCHW44 data layout, currently used in arm backend."
msgstr ""

#: megengine.jit.tracing.trace.dump:75 of
msgid "enable_nchw44_dot -- whether to use NCHW44_dot data layout, currently used in armv8.2+dotprod backend."
msgstr ""

#: megengine.jit.tracing.trace.dump:78 of
msgid "enable_nchw4 -- whether to use NCHW4 data layout, currently used in nvidia backend(based on cudnn)."
msgstr ""

#: megengine.jit.tracing.trace.dump:81 of
msgid "enable_nchw32 -- whether to use NCHW32 data layout, currently used in nvidia backend with tensorcore(based on cudnn)."
msgstr ""

#: megengine.jit.tracing.trace.dump:84 of
msgid "enable_chwn4 -- whether to use CHWN4 data layout, currently used in nvidia backend with tensorcore."
msgstr ""

#: megengine.jit.tracing.trace.dump:87 of
msgid "enable_nchw64 -- whether to use NCHW64 data layout, used for fast int4 support on Nvidia GPU."
msgstr ""

#: megengine.jit.tracing.trace.dump:90 of
msgid "enable_fuse_conv_bias_nonlinearity: whether to fuse conv+bias+nonlinearty into one opr."
msgstr ""

#: megengine.jit.tracing.trace.dump:92 of
msgid "enable_fuse_conv_bias_with_z: whether to fuse conv_bias with z input for inference on nvidia backend(this optimization pass will result in mismatch of the precision of output of training and inference)"
msgstr ""

#: megengine.jit.tracing.trace.dump:96 of
msgid "enable_fuse_preprocess: whether to fuse astype\\pad_channel\\dimshuffle and etc opr"
msgstr ""

#~ msgid "level for keeping variable names:"
#~ msgstr "保留变量名的级别:"

#~ msgid "0: none of the names are kept"
#~ msgstr "0: 不保留任何变量名"

#~ msgid "1: (default)keep names of output vars"
#~ msgstr "1(默认): 保留输出变量的名字"

#~ msgid "2: keep names of all (output and internal) vars"
#~ msgstr "2: 保留所有变量 (包括输出和中间变量) 的名字"

#~ msgid "enable_io16xc32 --"
#~ msgstr "enable_io16xc32 --"

#~ msgid "enable_ioc16 --"
#~ msgstr "enable_ioc16 --"

#~ msgid "enable_hwcd4 --"
#~ msgstr "enable_hwcd4 --"

#~ msgid "enable_nchw88 --"
#~ msgstr "enable_nchw88 --"

#~ msgid "enable_nchw44 --"
#~ msgstr "enable_nchw44 --"

#~ msgid "enable_nchw44_dot --"
#~ msgstr "enable_nchw44_dot --"

#~ msgid "enable_nchw4 --"
#~ msgstr "enable_nchw4 --"

#~ msgid "enable_nchw32 --"
#~ msgstr "enable_nchw32 --"

#~ msgid "enable_chwn4 --"
#~ msgstr "enable_chwn4 --"

#~ msgid "into one opr."
#~ msgstr "成一个算子。"

#~ msgid "enable_fuse_conv_bias_with_z: whether to fuse conv_bias with z"
#~ msgstr "enable_fuse_conv_bias_with_z："

