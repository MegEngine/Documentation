msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-09-01 21:02+0800\n"
"PO-Revision-Date: 2023-04-21 09:22\n"
"Last-Translator: \n"
"Language-Team: English\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: en\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/api/megengine.functional.quantized.batch_conv_bias_activation.po\n"
"X-Crowdin-File-ID: 9313\n"
"Language: en_US\n"

#: ../../source/reference/api/megengine.functional.quantized.batch_conv_bias_activation.rst:2
msgid "megengine.functional.quantized.batch\\_conv\\_bias\\_activation"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:1 of
msgid "Batch convolution bias with activation operation, only for inference."
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation of
msgid "参数"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:4 of
msgid "feature map of the convolution operation."
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:6 of
msgid "convolution kernel in batched way."
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:8 of
msgid "bias added to the result of convolution"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:10 of
msgid "stride of the 2D convolution operation. Default: 1"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:12 of
msgid "size of the paddings added to the input on both sides of its spatial dimensions. Only zero-padding is supported. Default: 0"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:15 of
msgid "dilation of the 2D convolution operation. Default: 1"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:17 of
msgid "number of groups into which the input and output channels are divided, so as to perform a \"grouped convolution\". When ``groups`` is not 1, ``in_channels`` and ``out_channels`` must be divisible by ``groups``, and the shape of weight should be `(groups, out_channel // groups, in_channels // groups, height, width)`."
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:22 of
msgid "supports 'cross_correlation' or 'convolution'. Default: 'cross_correlation'"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:24 of
msgid "support for ``np.dtype``, Default: np.int8"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:25 of
msgid "when set to \"default\", no special requirements will be placed on the precision of intermediate results. When set to \"float32\", \"float32\" would be used for accumulator and intermediate result, but only effective when input and output are of float16 dtype."
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation of
msgid "返回类型"
msgstr ""

#: megengine.functional.quantized.batch_conv_bias_activation:31 of
msgid ":py:class:`~megengine.tensor.Tensor`"
msgstr ""

