
msgid ""
msgstr ""
"Project-Id-Version:  megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-09-14 06:50+0000\n"
"PO-Revision-Date: 2023-04-21 09:12+0000\n"
"Last-Translator: \n"
"Language: en_US\n"
"Language-Team: English\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"

#: ../../source/reference/api/megengine.amp.GradScaler.rst:5
msgid "GradScaler"
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:1 of
msgid ""
"A helper class that performs grad scaling to prevent from data overflow "
"in :class:`~.autocast` mode."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler
#: megengine.amp.grad_scaler.GradScaler.backward
#: megengine.amp.grad_scaler.GradScaler.unscale of
msgid "参数"
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:5 of
msgid "initial scale factor."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:7 of
msgid ""
"factor that the scale is multiplied by in actual :meth:`update` stage. If"
" growth_factor is 0, scale_factor will not update."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:10 of
msgid "factor that the scale is multiplied by when encountering overflow grad."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:13 of
msgid "the interval between two scale update stages."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler of
msgid "返回"
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:15 of
msgid "gradScaler object."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:18 of
msgid "示例"
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:36 of
msgid ""
"If need more flexible usage, could split ``scaler.backward`` into three "
"lines:"
msgstr ""

#: megengine.amp.grad_scaler.GradScaler:51 of
msgid "This is useful when need to accumulate grads for multi batches."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.backward:1 of
msgid ""
"A wrapper of GradManager's :meth:`~.GradManager.backward`, used to scale "
"``y``'s grad and unscale parameters' grads."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.backward:5 of
msgid "The to be wrapped GradManager."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.backward:7 of
msgid "Same as GradManager backward's ``y``."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.backward:9 of
msgid ""
"Same as GradManager backward's ``dy``. Will be multiplied by "
"``scale_factor``."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.backward:12 of
msgid ""
"Whether do :meth:`unscale` at the same time. Could be ``False`` if needs "
"to accumulate grads."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.backward:15 of
msgid ""
"Same as :meth:`unscale`'s ``update``. Will be ignored if ``unscale_grad``"
" is ``False``."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.unscale:1 of
msgid "Unscale all ``grad_tensors``'s grad."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.unscale:4 of
msgid ""
"Tensors needed to unscale grads. Should be all tensors that are affected "
"by ``target`` tensor in GradManager's backward."
msgstr ""

#: megengine.amp.grad_scaler.GradScaler.update:1 of
msgid ""
"Update the scale factor according to whether encountered overflow grad. "
"If ``new_scale`` is provided, internal update mechanism will be ignored."
msgstr ""

#~ msgid "Initial scale factor."
#~ msgstr ""

#~ msgid ""
#~ "Factor that the scale is multiplied "
#~ "by in actual :meth:`update` stage. If"
#~ " growth_factor is 0, scale_factor will "
#~ "not update."
#~ msgstr ""

#~ msgid "Factor that the scale is multiplied by when encountering overflow grad."
#~ msgstr ""

#~ msgid "The interval between two scale update stages."
#~ msgstr ""

