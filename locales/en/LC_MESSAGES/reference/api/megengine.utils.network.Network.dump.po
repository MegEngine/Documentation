# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020-2021, The MegEngine Open Source Team
# This file is distributed under the same license as the MegEngine package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MegEngine 1.3.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-09 17:59+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"

#: ../../source/reference/api/megengine.utils.network.Network.dump.rst:2
msgid "megengine.utils.network.Network.dump"
msgstr ""

#: megengine.utils.network.Network.dump:1 of
msgid "Serializes graph to file."
msgstr ""

#: megengine.utils.network.Network.dump of
msgid "参数"
msgstr ""

#: megengine.utils.network.Network.dump:3 of
msgid "output file, could be file object or filename."
msgstr ""

#: megengine.utils.network.Network.dump:4 of
msgid "whether output is appended to ``file``. Only works when ``file`` is str."
msgstr ""

#: megengine.utils.network.Network.dump:7 of
msgid ""
"level for keeping variable names:  * 0: none of the names are kept * 1: "
"(default)keep names of output vars * 2: keep names of all (output and "
"internal) vars"
msgstr ""

#: megengine.utils.network.Network.dump:7 of
msgid "level for keeping variable names:"
msgstr ""

#: megengine.utils.network.Network.dump:9 of
msgid "0: none of the names are kept"
msgstr ""

#: megengine.utils.network.Network.dump:10 of
msgid "1: (default)keep names of output vars"
msgstr ""

#: megengine.utils.network.Network.dump:11 of
msgid "2: keep names of all (output and internal) vars"
msgstr ""

#: megengine.utils.network.Network.dump:13 of
msgid "whether to keep operator names."
msgstr ""

#: megengine.utils.network.Network.dump:15 of
msgid ""
"whether to keep param names, so param values can be easily manipulated "
"after loading model"
msgstr ""

#: megengine.utils.network.Network.dump:18 of
msgid "whether to keep priority setting for operators"
msgstr ""

#: megengine.utils.network.Network.dump:19 of
msgid ""
"a string for path or a file handler. if is not None, then the dump "
"information for code strip would be written to ``strip_info_file``"
msgstr ""

#: megengine.utils.network.Network.dump:21 of
msgid ""
"will be check when `strip_info_file` is not None. if set true, the "
"information for code strip will be append to strip_info_file. if set "
"false, will rewrite strip_info_file"
msgstr ""

#: megengine.utils.network.Network.dump:24 of
msgid ""
"enbale optmizations, will skip all optimize options if this is False. "
"Default: True"
msgstr ""

#: megengine.utils.network.Network.dump of
msgid "Keyword Arguments"
msgstr ""

#: megengine.utils.network.Network.dump:31 of
msgid "enable_io16xc32 --"
msgstr ""

#: megengine.utils.network.Network.dump:30 of
msgid ""
"whether to use float16 for I/O between oprs and use float32 as internal "
"computation precision. Note the output var would be changed to float16."
msgstr ""

#: megengine.utils.network.Network.dump:35 of
msgid "enable_ioc16 --"
msgstr ""

#: megengine.utils.network.Network.dump:34 of
msgid "whether to use float16 for both I/O and computation precision."
msgstr ""

#: megengine.utils.network.Network.dump:38 of
msgid "enable_hwcd4 --"
msgstr ""

#: megengine.utils.network.Network.dump:38 of
msgid "whether to use NHWCD4 data layout. This is faster on some OpenCL backend."
msgstr ""

#: megengine.utils.network.Network.dump:41 of
msgid "enable_nchw88 --"
msgstr ""

#: megengine.utils.network.Network.dump:41 of
msgid "whether to use NCHW88 data layout, currently used in X86 AVX backend."
msgstr ""

#: megengine.utils.network.Network.dump:44 of
msgid "enable_nchw44 --"
msgstr ""

#: megengine.utils.network.Network.dump:44 of
msgid "whether to use NCHW44 data layout, currently used in arm backend."
msgstr ""

#: megengine.utils.network.Network.dump:47 of
msgid "enable_nchw44_dot --"
msgstr ""

#: megengine.utils.network.Network.dump:47 of
msgid ""
"whether to use NCHW44_dot data layout, currently used in armv8.2+dotprod "
"backend."
msgstr ""

#: megengine.utils.network.Network.dump:50 of
msgid "enable_nchw4 --"
msgstr ""

#: megengine.utils.network.Network.dump:50 of
msgid ""
"whether to use NCHW4 data layout, currently used in nvidia backend(based "
"on cudnn)."
msgstr ""

#: megengine.utils.network.Network.dump:53 of
msgid "enable_nchw32 --"
msgstr ""

#: megengine.utils.network.Network.dump:53 of
msgid ""
"whether to use NCHW32 data layout, currently used in nvidia backend with "
"tensorcore(based on cudnn)."
msgstr ""

#: megengine.utils.network.Network.dump:57 of
msgid "enable_chwn4 --"
msgstr ""

#: megengine.utils.network.Network.dump:56 of
msgid ""
"whether to use CHWN4 data layout, currently used in nvidia backend with "
"tensorcore."
msgstr ""

#: megengine.utils.network.Network.dump:59 of
msgid "enable_fuse_conv_bias_nonlinearity: whether to fuse conv+bias+nonlinearty"
msgstr ""

#: megengine.utils.network.Network.dump:60 of
msgid "into one opr."
msgstr ""

#: megengine.utils.network.Network.dump:63 of
msgid "enable_fuse_conv_bias_with_z: whether to fuse conv_bias with z"
msgstr ""

#: megengine.utils.network.Network.dump:62 of
msgid ""
"input for inference on nvidia backend(this optimization pass will result "
"in mismatch of the precision of output of training and inference)"
msgstr ""

