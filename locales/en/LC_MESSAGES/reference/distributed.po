msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-12-24 23:51+0800\n"
"PO-Revision-Date: 2023-04-21 09:32\n"
"Last-Translator: \n"
"Language: en_US\n"
"Language-Team: English\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: en\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/distributed.po\n"
"X-Crowdin-File-ID: 9785\n"

#: ../../source/reference/distributed.rst:6
msgid "megengine.distributed"
msgstr ""

#: ../../source/reference/distributed.rst:16:<autosummary>:1
msgid ":py:obj:`backend <megengine.distributed.backend>`"
msgstr ""

#: ../../source/reference/distributed.rst:16:<autosummary>:1
msgid "Get or set backend of collective communication."
msgstr ""

#: ../../source/reference/distributed.rst:18
msgid "分组（Group）"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`Server <megengine.distributed.Server>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Distributed Server for distributed training."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`Group <megengine.distributed.Group>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Include ranked nodes running collective communication (See :mod:`~.functional.distributed`)."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`init_process_group <megengine.distributed.init_process_group>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Initialize the distributed process group and specify the device used in the current process"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`new_group <megengine.distributed.new_group>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Build a subgroup containing certain ranks."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`group_barrier <megengine.distributed.group_barrier>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Block until all ranks in the group reach this barrier."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`override_backend <megengine.distributed.override_backend>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Override distributed backend"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`is_distributed <megengine.distributed.is_distributed>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Return True if the distributed process group has been initialized."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`get_backend <megengine.distributed.get_backend>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Get the backend str."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`get_client <megengine.distributed.get_client>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Get client of python XML RPC server."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`get_mm_server_addr <megengine.distributed.get_mm_server_addr>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Get master_ip and port of C++ mm_server."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`get_py_server_addr <megengine.distributed.get_py_server_addr>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Get master_ip and port of python XML RPC server."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`get_rank <megengine.distributed.get_rank>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Get the rank of the current process."
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid ":py:obj:`get_world_size <megengine.distributed.get_world_size>`"
msgstr ""

#: ../../source/reference/distributed.rst:37:<autosummary>:1
msgid "Get the total number of processes participating in the job."
msgstr ""

#: ../../source/reference/distributed.rst:39
msgid "运行器（Launcher）"
msgstr ""

#: ../../source/reference/distributed.rst:45:<autosummary>:1
msgid ":py:obj:`launcher <megengine.distributed.launcher>`"
msgstr ""

#: ../../source/reference/distributed.rst:45:<autosummary>:1
msgid "Decorator for launching multiple processes in single-machine multi-gpu training."
msgstr ""

#: ../../source/reference/distributed.rst:47
msgid "辅助功能（Helper）"
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid ":py:obj:`bcast_list_ <megengine.distributed.bcast_list_>`"
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid "Broadcast tensors between given group."
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid ":py:obj:`synchronized <megengine.distributed.synchronized>`"
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid "Decorator."
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid ":py:obj:`make_allreduce_cb <megengine.distributed.make_allreduce_cb>`"
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid "alias of :py:class:`megengine.distributed.helper.AllreduceCallback`"
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid ":py:obj:`helper.AllreduceCallback <megengine.distributed.helper.AllreduceCallback>`"
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid "Allreduce Callback with tensor fusion optimization."
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid ":py:obj:`helper.param_pack_split <megengine.distributed.helper.param_pack_split>`"
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid "Returns split tensor to list of tensors as offsets and shapes described, only used for ``parampack``."
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid ":py:obj:`helper.param_pack_concat <megengine.distributed.helper.param_pack_concat>`"
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid "Returns concated tensor, only used for ``parampack``."
msgstr ""

#: ../../source/reference/distributed.rst:58:<autosummary>:1
msgid ":py:obj:`helper.pack_allreduce_split <megengine.distributed.helper.pack_allreduce_split>`"
msgstr ""

#~ msgid "分布式训练（Distributed）"
#~ msgstr "分布式训练（Distributed）"

#~ msgid ":obj:`backend <megengine.distributed.backend>`"
#~ msgstr ""

#~ msgid ":obj:`Group <megengine.distributed.Group>`"
#~ msgstr ""

#~ msgid ":obj:`init_process_group <megengine.distributed.init_process_group>`"
#~ msgstr ""

#~ msgid ":obj:`new_group <megengine.distributed.new_group>`"
#~ msgstr ""

#~ msgid ":obj:`is_distributed <megengine.distributed.is_distributed>`"
#~ msgstr ""

#~ msgid ":obj:`get_backend <megengine.distributed.get_backend>`"
#~ msgstr ""

#~ msgid ":obj:`get_client <megengine.distributed.get_client>`"
#~ msgstr ""

#~ msgid ":obj:`get_mm_server_addr <megengine.distributed.get_mm_server_addr>`"
#~ msgstr ""

#~ msgid ":obj:`get_py_server_addr <megengine.distributed.get_py_server_addr>`"
#~ msgstr ""

#~ msgid ":obj:`get_rank <megengine.distributed.get_rank>`"
#~ msgstr ""

#~ msgid ":obj:`get_world_size <megengine.distributed.get_world_size>`"
#~ msgstr ""

#~ msgid ":obj:`group_barrier <megengine.distributed.group_barrier>`"
#~ msgstr ""

#~ msgid ":obj:`launcher <megengine.distributed.launcher>`"
#~ msgstr ""

#~ msgid ":obj:`Client <megengine.distributed.Client>`"
#~ msgstr ""

#~ msgid ":obj:`Server <megengine.distributed.Server>`"
#~ msgstr ""

#~ msgid ":obj:`bcast_list_ <megengine.distributed.bcast_list_>`"
#~ msgstr ""

#~ msgid ":obj:`synchronized <megengine.distributed.synchronized>`"
#~ msgstr ""

#~ msgid ":obj:`make_allreduce_cb <megengine.distributed.make_allreduce_cb>`"
#~ msgstr ""

#~ msgid "alias of :class:`megengine.distributed.helper.AllreduceCallback`"
#~ msgstr ""

#~ msgid ""
#~ ":obj:`helper.AllreduceCallback "
#~ "<megengine.distributed.helper.AllreduceCallback>`"
#~ msgstr ""

#~ msgid "客户端与服务端(C/S)"
#~ msgstr ""

#~ msgid ":py:obj:`Client <megengine.distributed.Client>`"
#~ msgstr ""

#~ msgid "Distributed Client for distributed training."
#~ msgstr "分布式训练的分布式客户端。"

