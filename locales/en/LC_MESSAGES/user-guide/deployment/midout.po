msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-12-08 20:45+0800\n"
"PO-Revision-Date: 2023-04-21 09:35\n"
"Last-Translator: \n"
"Language: en_US\n"
"Language-Team: English\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: en\n"
"X-Crowdin-File: /dev/locales/en/LC_MESSAGES/user-guide/deployment/midout.po\n"
"X-Crowdin-File-ID: 9893\n"

#: ../../source/user-guide/deployment/midout.rst:5
msgid "减少二进制文件体积"
msgstr "Reduce the size of binary files"

#: ../../source/user-guide/deployment/midout.rst:7
msgid "midout 是 MegEngine 中用来减小生成的二进制文件体积的工具，有助于在空间受限的设备上部署应用。 midout 通过记录模型推理时用到的 opr 和执行流，使用 ``if(0)`` 关闭未被记录的代码段后重新编译， 利用 ``-ffunction-sections -fdata-sections -Wl,--gc-sections -flto`` 链接参数，可以大幅度减少静态链接的可执行文件的大小。 现在基于 MegEngine 提供模型验证工具 :ref:`Load and Run <load-and-run>` , 展示怎样在某 AArch64 架构的 Android 端上裁剪 MegEngine 库。"
msgstr "midout is a tool in MegEngine to reduce the size of the generated binaries, which is helpful for deploying applications on space-constrained devices. midout records the opr and execution flow used in model inference, uses ``if(0)`` to close unrecorded code segments and recompiles, and uses ``-ffunction-sections -fdata-sections -Wl,-- The gc-sections -flto link parameter can drastically reduce the size of statically linked executables. Now provides model verification tool :ref:`Load and Run 1` based <load-and-run>MegEngine, showing how to tailor MegEngine library on the Android side of an AArch64 architecture."

#: ../../source/user-guide/deployment/midout.rst:14
msgid "编译静态链接的 load_and_run"
msgstr "Compile statically linked load_and_run"

#: ../../source/user-guide/deployment/midout.rst:16
msgid "端上裁剪 MegEngine 库需要一个静态连接 MegEngine 的可执行程序，编译方法详见 load-and-run 的编译部分。 稍有不同的是编译时需要先设置 load_and_run 静态链接 MegEngine."
msgstr "Tailoring the MegEngine library on the end requires an executable program that is statically connected to the MegEngine. For the compilation method, see the compilation part of load-and-run. The slight difference is that you need to set load_and_run to statically link MegEngine when compiling."

#: ../../source/user-guide/deployment/midout.rst:23
msgid "查看一下 load_and_run 的大小："
msgstr "Check the size of load_and_run："

#: ../../source/user-guide/deployment/midout.rst:30
msgid "此时 load_and_run 大小超过 20MB. load_and_run 的执行，请参考下文“代码执行”部分。"
msgstr "At this time, the size of load_and_run exceeds 20MB. For the execution of load_and_run, please refer to the \"Code Execution\" section below."

#: ../../source/user-guide/deployment/midout.rst:33
msgid "裁剪 load_and_run"
msgstr "Crop load_and_run"

#: ../../source/user-guide/deployment/midout.rst:35
msgid "MegEngine 的裁剪可以从两方面进行："
msgstr "MegEngine cut two ways can be："

#: ../../source/user-guide/deployment/midout.rst:37
msgid "通过opr 裁剪。在 dump 模型时，可以同时将模型用到的 opr 信息以 json 文件的形式输出， midout 在编译期裁掉没有被模型使用到的所有 opr."
msgstr "Cut through opr. When dumping the model, the opr information used by the model can be output in the form of a json file at the same time, and midout will cut off all opr not used by the model during the compile time."

#: ../../source/user-guide/deployment/midout.rst:39
msgid "通过 trace 流裁剪。运行一次模型推理，根据代码的执行流生成 trace 文件， 通过trace文件，在二次编译时将没有执行的代码段裁剪掉。"
msgstr "Tailor through the trace stream. Run the model inference once, and generate a trace file according to the execution flow of the code. Through the trace file, the code segments that are not executed during the second compilation are cut out."

#: ../../source/user-guide/deployment/midout.rst:42
msgid "整个裁剪过程分为两个步骤："
msgstr "The entire two-step cutting process："

#: ../../source/user-guide/deployment/midout.rst:44
msgid "第一步，dump 模型，获得模型 opr 信息；通过一次推理，获得 trace 文件。"
msgstr "The first step is to dump the model to obtain model opr information; to obtain the trace file through an inference."

#: ../../source/user-guide/deployment/midout.rst:45
msgid "第二步，使用MegEngine的头文件生成工具 ``tools/gen_header_for_bin_reduce.py`` 将 opr 信息和 trace 文件作为输入， 生成 ``src/bin_reduce_cmake.h`` CMake 会自动维护这个文件，用户无需关心。 当然也可以单独使用模型 opr 信息或是 trace 文件来生成 ``src/bin_reduce_cmake.h`` ， 单独使用 opr 信息时，默认保留所有 kernel，单独使用 trace 文件时，默认保留所有 opr."
msgstr "In the second step, use MegEngine's header file generation tool ``tools/gen_header_for_bin_reduce.py`` to take the opr information and trace file as input, and generate ``src/bin_reduce_cmake.h`` CMake will automatically maintain this file, and the user does not need to care. Of course, you can also use the model opr information or trace file alone to generate ``src/bin_reduce_cmake.h``. When using opr information alone, all kernels are retained by default, and when trace files are used alone, all opr are retained by default."

#: ../../source/user-guide/deployment/midout.rst:51
msgid "dump 模型获得 opr 类型名称"
msgstr "dump model to get the opr type name"

#: ../../source/user-guide/deployment/midout.rst:53
msgid "一个模型通常不会用到所有的opr，根据模型使用的opr，可以裁掉那些模型没有使用的 opr. 在转换模型时，我们可以通过如下方式获得模型的 opr 信息。 使用 ``megengine.jit.trace.dump`` 准备模型时，设置 ``strip_info_file`` 参数。"
msgstr "A model usually does not use all opr. According to the opr used by the model, the opr that is not used by the model can be cut off. When converting the model, we can obtain the opr information of the model in the following ways. When using ``megengine.jit.trace.dump`` to prepare the model, set the ``strip_info_file`` parameter."

#: ../../source/user-guide/deployment/midout.rst:61
msgid "执行完毕后，会生成 ``resnet50.mge`` 和 ``resnet50.mge.json`` . 查看这个 JSON 文件，它记录了模型用到的 opr 名称。"
msgstr "After the execution is completed, ``resnet50.mge`` and ``resnet50.mge.json`` will be generated. Check this JSON file, it records the opr name used by the model."

#: ../../source/user-guide/deployment/midout.rst:69
msgid "执行模型获得 trace 文件"
msgstr "Execute the model to obtain the trace file"

#: ../../source/user-guide/deployment/midout.rst:71
msgid "基于 trace 的裁剪需要通过一次推理获得模型的执行 trace 文件。具体步骤如下："
msgstr "Tailoring based on trace requires one inference to obtain the execution trace file of the model. The specific steps are as："

#: ../../source/user-guide/deployment/midout.rst:73
msgid "CMake 构建时，打开 ``MGE_WITH_MIDOUT_PROFILE`` 开关，编译 load_and_run："
msgstr "When CMake is building, turn on the ``MGE_WITH_MIDOUT_PROFILE`` switch and compile load_and_run："

#: ../../source/user-guide/deployment/midout.rst:79
msgid "编译完成后，将 ``build_dir/android/arm64-v8a/Release/install/bin`` 下的 ``load_and_run`` 推至设备并执行："
msgstr "After the compilation is complete, push the ``load_and_run'' under ``build_dir/android/arm64-v8a/Release/install/bin'' to the device and execute："

#: ../../source/user-guide/deployment/midout.rst:85
msgid "得到如下输出："
msgstr "Get the following output："

#: ../../source/user-guide/deployment/midout.rst:110
msgid "注意到执行模型后，生成了 ``midout_trace.20717`` 文件，该文件记录了模型在底层执行了哪些 kernel."
msgstr "After noticing that the model is executed, the ``midout_trace.20717'' file is generated, which records which kernels the model has executed at the bottom."

#: ../../source/user-guide/deployment/midout.rst:112
msgid "生成 ``src/bin_reduce_cmake.h`` 并再次编译 load_and_run："
msgstr "Generate ``src/bin_reduce_cmake.h`` and compile load_and_run：again"

#: ../../source/user-guide/deployment/midout.rst:114
msgid "将生成的 ``midout_trace.20717`` 拷贝至本地， 使用上文提到的头文件生成工具 ``gen_header_for_bin_reduce.py`` 生成 ``src/bin_reduce_cmake.h`` ."
msgstr "Copy the generated ``midout_trace.20717`` to the local, and use the above-mentioned header file generation tool ``gen_header_for_bin_reduce.py`` to generate ``src/bin_reduce_cmake.h``."

#: ../../source/user-guide/deployment/midout.rst:123
msgid "编译完成后，检查 load_and_run 的大小, 注意 MGE_WITH_MINIMUM_SIZE 不是非必须的，加上它 size 会更小，但同时会关闭一些编译选项："
msgstr "After the compilation is complete, check the size of load_and_run, note that MGE_WITH_MINIMUM_SIZE is not necessary, plus its size will be smaller, but at the same time some compilation options will be turned off："

#: ../../source/user-guide/deployment/midout.rst:130
msgid "此时 load_and_run 的大小减小到 2MB 多。推到设备上运行，得到如下输出："
msgstr "At this time, the size of load_and_run is reduced to more than 2MB. Push to the device to run, get the following output："

#: ../../source/user-guide/deployment/midout.rst:155
msgid "可以看到模型依然正常运行，并且运行速度正常。"
msgstr "You can see that the model is still running normally, and the running speed is normal."

#: ../../source/user-guide/deployment/midout.rst:158
msgid "使用裁剪后的 load_and_run"
msgstr "Use cropped load_and_run"

#: ../../source/user-guide/deployment/midout.rst:160
msgid "想要裁剪前后的应用能够正常运行，需要保证裁剪前后两次推理使用同样的命令行参数。 如果使用上文裁剪的 load_and_fun 的 fast-run功能（详见 :ref:`load-and-run` ）。"
msgstr "If you want the application before and after cutting to run normally, you need to ensure that the same command line parameters are used for the two inferences before and after cutting. If you use the fast-run function of load_and_fun cut above (see :ref:`load-and-run` for details)."

#: ../../source/user-guide/deployment/midout.rst:167
msgid "可能得到如下输出："
msgstr "You may get the following output："

#: ../../source/user-guide/deployment/midout.rst:178
msgid "这是因为程序运行到了已经被裁剪掉的函数中，未被记录在 trace 文件中的函数的实现已经被替换成 ``trap()`` . 如果想要裁剪与 fast-run 配合使用，需要按如下流程获得 trace 文件："
msgstr "This is because the program runs into a function that has been trimmed, and the implementation of the function that is not recorded in the trace file has been replaced with ``trap()``. If you want to trim and use fast-run, you need to press the following process to obtain trace files："

#: ../../source/user-guide/deployment/midout.rst:181
msgid "开启 fast-run 模式，执行未裁剪的 load_and_run 获得 ``.cache`` 文件，注意本次执行生成的 trace 应该被丢弃："
msgstr "Turn on fast-run mode, execute uncropped load_and_run to obtain the ``.cache`` file, note that the trace generated by this execution should be discarded："

#: ../../source/user-guide/deployment/midout.rst:187
msgid "使用 ``.cache`` 文件，执行 load_and_run 获得 trace 文件："
msgstr "Use the ``.cache`` file, execute load_and_run to get the trace file："

#: ../../source/user-guide/deployment/midout.rst:193
msgid "如上节，将 trace 文件拷贝回本机，生成 ``src/bin_reduce_cmake.h`` ，再次编译 load_and_run 并推至设备。"
msgstr "As in the previous section, copy the trace file back to the local machine, generate ``src/bin_reduce_cmake.h``, compile load_and_run again and push it to the device."

#: ../../source/user-guide/deployment/midout.rst:195
msgid "使用裁剪后的 load_and_run 的 fast-run 功能，执行同 2 的命令，得到如下输出："
msgstr "Use the fast-run function of the cropped load_and_run and execute the same command as 2 to get the following output："

#: ../../source/user-guide/deployment/midout.rst:221
msgid "使用其他 load_and_run 提供的功能也是如此，想要裁剪前后的应用能够正常运行， 需要保证裁剪前后两次推理使用同样的命令行参数。"
msgstr "The same is true for other functions provided by load_and_run. If the application before and after cutting can run normally, it is necessary to ensure that the same command line parameters are used for the two inferences before and after cutting."

#: ../../source/user-guide/deployment/midout.rst:225
msgid "多个模型合并裁剪"
msgstr "Merge and crop multiple models"

#: ../../source/user-guide/deployment/midout.rst:226
msgid "多个模型的合并裁剪与单个模型流程相同。 ``gen_header_for_bin_reduce.py`` 接受多个输入。 假设有模型 A 与模型 B, 已经获得 ``A.mge.json`` , ``B.mge.json`` 以及 ``A.trace`` , ``B.trace`` . 执行："
msgstr "The process of merging and cutting multiple models is the same as that of a single model. ``gen_header_for_bin_reduce.py`` accepts multiple inputs. Suppose there are model A and model B, and have obtained ``A.mge.json``, ``B.mge.json`` and ``A.trace``, ``B.trace``. Go to："

#: ../../source/user-guide/deployment/midout.rst:234
msgid "裁剪基于 MegEngine 的应用"
msgstr "Tailor MegEngine-based applications"

#: ../../source/user-guide/deployment/midout.rst:236
msgid "可以通过如下几种方式集成 MegEngine，对应的裁剪方法相差无几："
msgstr "MegEngine may be integrated by several ways, corresponding to almost the same method of clipping："

#: ../../source/user-guide/deployment/midout.rst:238
msgid "参照 ``CMakeLists.txt`` ，将应用集成到整个 MegEngine 的工程。 假设已经将 ``app.cpp`` 集成到 MegEngine ，那么会编译出静态链接 MegEngine 的可执行程序 ``app`` . 只需要按照上文中裁剪 load_and_run 的流程裁剪 ``app`` 即可。"
msgstr "Refer to ``CMakeLists.txt`` to integrate the application into the entire MegEngine project. Assuming that ``app.cpp`` has been integrated into MegEngine, then the executable program ``app`` of statically linked MegEngine will be compiled. Just follow the process of cutting load_and_run above to cut ``app``."

#: ../../source/user-guide/deployment/midout.rst:241
msgid "可能一个应用想要通过静态库集成 MegEngine。此时需要获得一个裁剪过的 ``libmegengine.a`` . 可以依然使用 load_and_run 运行模型获得 trace 文件， 生成 ``src/bin_reduce_cmake.h`` ，并二次编译获得裁剪过的 ``libmegengine.a`` . 此时，用户使用自己编写的构建脚本构建应用程序，并静态链接 ``libmegengine.a`` ， 加上链接参数 ``-flto=full -ffunction-sections -fdata-sections -Wl,--gc-sections`` . 即可得到裁剪过的基于 MegEngine 的应用。"
msgstr "Maybe an application wants to integrate MegEngine via a static library. At this point, you need to get a trimmed ``libmegengine.a``. You can still use load_and_run to run the model to get the trace file, generate ``src/bin_reduce_cmake.h``, and compile it again to get the trimmed ``libmegengine.a' `` . At this point, the user builds the application using the build script written by himself, and statically links ``libmegengine.a``, plus the link parameter ``-flto=full -ffunction-sections -fdata-sections -Wl,- -gc-sections`` . You can get a tailored MegEngine-based application."

#: ../../source/user-guide/deployment/midout.rst:246
msgid "上述流程亦可以用于 ``libmegengine.so`` 的裁剪，但是动态库的裁剪效果远不及静态库。 原因在于 libmegengine.so 没有做符号隐藏，因此链接器不会进行激进的优化。"
msgstr "The above process can also be used for clipping of ``libmegengine.so``, but the clipping effect of dynamic libraries is far less than that of static libraries. The reason is that libmegengine.so doesn't do symbol hiding, so the linker doesn't do aggressive optimizations."

#: ../../source/user-guide/deployment/midout.rst:248
msgid "经过上述流程，同样会在 build_dir 目录生成 liblite_shared.so, 此库裁剪力度和app裁剪效果相当，推荐这种方式。"
msgstr "After the above process, liblite_shared.so will also be generated in the build_dir directory. The clipping force of this library is equivalent to the app clipping effect. This method is recommended."

#: ../../source/user-guide/deployment/midout.rst:249
msgid "经过上述流程，同样会在 build_dir 目录生成 liblite_static_all_in_one.a, 此库裁剪力度和app裁剪效果相当，也推荐这种方式, 同样需要在自己集成的构建系统加上链接参数 ``-flto=full -ffunction-sections -fdata-sections -Wl,--gc-sections``"
msgstr "After the above process, liblite_static_all_in_one.a will also be generated in the build_dir directory. The clipping effect of this library is equivalent to the app clipping effect. This method is also recommended. It is also necessary to add the link parameter ``-flto=full -ffunction to the integrated build system. -sections -fdata-sections -Wl,--gc-sections``"

#: ../../source/user-guide/deployment/midout.rst:251
msgid "所有基于静态库集成的地方， 如果输出是一个动态库， 则需要自己维护最终目标的符号隐藏，才能达到最佳裁剪效果， 为了方便， 强烈建议直接集成 liblite_shared.so."
msgstr "All places based on static library integration, if the output is a dynamic library, you need to maintain the symbol hiding of the final target to achieve the best cutting effect. For convenience, it is strongly recommended to directly integrate liblite_shared.so."

#~ msgid "否则，MegEngine 会自动编译成动态库。然后执行："
#~ msgstr ""
#~ "Otherwise, MegEngine will be automatically "
#~ "compiled into a dynamic library. Then"
#~ " execute："

#~ msgid "再次编译 load_and_run，注意要将 ``bin_reduce.h`` 加入并编译 Release 版本。设置 CMake 编译选项："
#~ msgstr ""
#~ "Compile load_and_run again, pay attention "
#~ "to adding ``bin_reduce.h`` and compile "
#~ "the Release version. Setting CMake "
#~ "compiler option："

#~ msgid "编译完成后，检查 load_and_run 的大小："
#~ msgstr "After compiling, check the size of load_and_run："

#~ msgid "编译选项"
#~ msgstr "Compilation options"

#~ msgid ""
#~ "MegEngine 的 CMake 中有一些开关是默认打开的，它们提供了 "
#~ "RTTI、异常抛出等特性， 可以在第二次构建时关闭它们，以获得体积更小的 load_and_run. "
#~ "它们是："
#~ msgstr ""
#~ "There are some switches in MegEngine's"
#~ " CMake that are turned on by "
#~ "default. They provide features such as"
#~ " RTTI and exception throwing. You can"
#~ " turn them off during the second "
#~ "build to get a smaller load_and_run. "
#~ "They are："

#~ msgid "``MGB_WITH_FLATBUFFERS`` : FLABUFFERS格式支持"
#~ msgstr "``MGB_WITH_FLATBUFFERS``: FLABUFFERS format support"

#~ msgid "``MGE_ENABLE_RTTI`` : C++ RTTI特性"
#~ msgstr "``MGE_ENABLE_RTTI``: C++ RTTI features"

#~ msgid "``MGE_ENABLE_LOGGING`` : 日志功能"
#~ msgstr "``MGE_ENABLE_LOGGING``: log function"

#~ msgid "``MGE_ENABLE_EXCEPTIONS`` : 异常功能"
#~ msgstr "``MGE_ENABLE_EXCEPTIONS``: abnormal function"

#~ msgid ""
#~ "MegEngine 提供一个总开关 ``MGE_WITH_MINIMUM_SIZE`` 来关闭上述特性。"
#~ " 需要注意的是，只有在 ``MGE_BIN_REDUCE`` 被设置时，此开关才会被检查并生效。"
#~ msgstr ""
#~ "MegEngine provides a master switch "
#~ "``MGE_WITH_MINIMUM_SIZE'' to turn off the "
#~ "above features. It should be noted "
#~ "that this switch will be checked "
#~ "and effective only when ``MGE_BIN_REDUCE`` "
#~ "is set."

