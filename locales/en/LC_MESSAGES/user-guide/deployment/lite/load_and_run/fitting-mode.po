# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020-2022, The MegEngine Open Source Team
# This file is distributed under the same license as the MegEngine package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MegEngine 1.10\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-07-26 13:50+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:4
msgid "使用 Load and run 自动获取最优推理加速配置参数"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:6
msgid ""
"使用 Load and run 进行模型推理测速时，MegEngine 提供了大量的配置选项用于探索针对特定模型的推理加速。 "
"这些配置选项灵活繁多，对于模型开发者而言有一定的启发意义。但对于部署而言，繁多的选项意味着较大的用户使用负担。 "
"为了减少部署时用户的使用负担，Load and run 实现了 fitting 模式用于自动的进行推理时最优配置选项的选择， "
"减少部署时用户使用负担，提高用户使用体验。"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:12
msgid "准备工作"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:15
msgid "编译 Load and run"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:17
msgid ""
"如果只需要使用 Load and run 来获取给定平台上的最优配置，正常编译即可，编译过程参考 :ref:`compile-load-and-"
"run` 如果需要将相应配置，模型以及相关缓存打包，由于需要用到megengine json相关的部分，编译时需要开启相关设置："
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:25
msgid "准备模型"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:29
msgid "fitting 模式在不打包模型的情况下，可以支持 MegEngine Lite, MegEngine 的模型"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:31
msgid "fitting 模式如果需要打包模型，目前支持 MegEngine 的模型，其他类型的模型由于接口原因，暂时不支持打包操作"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:34
msgid "使用fitting 获取模型最优的推理配置"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:38
msgid "fitting 默认的推理后端为XPU，在有CUDA的设备上默认使用GPU,其他设备上默认使用CPU."
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:40
msgid "基本流程"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:46
msgid "常见用法"
msgstr ""

#: ../../source/user-guide/deployment/lite/load_and_run/fitting-mode.rst:56
msgid "模型dump"
msgstr ""

