msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-11-08 21:51+0800\n"
"PO-Revision-Date: 2021-11-12 00:51\n"
"Last-Translator: \n"
"Language-Team: English\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: en\n"
"X-Crowdin-File: /[MegEngine.Documentation] main/locales/en/LC_MESSAGES/user-guide/deployment/lite/pylite-advanced.po\n"
"X-Crowdin-File-ID: 8211\n"
"Language: en_US\n"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:5
msgid "MegEngine Lite Python 进阶实例"
msgstr "MegEngine Lite Python advanced example"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:7
msgid "Lite 的 Python 封装将随着 Lite 一起开源。"
msgstr "Lite's Python package will be open source along with Lite."

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:10
msgid "Python 推理接口"
msgstr "Python inference interface"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:12
msgid "Lite 的 python 封装里主要有两个类：**LiteTensor** 和 **LiteNetwork** 。"
msgstr "There are two main classes in Lite's python package：**LiteTensor** and **LiteNetwork**."

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:15
msgid "LiteTensor"
msgstr "LiteTensor"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:17
msgid "**LiteTensor** 提供了用户对数据的操作接口，提供了接口包括:"
msgstr "**LiteTensor** provides an interface for users to manipulate data, including:"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:19
msgid "``fill_zero()``: 将tensor的内存设置为全0"
msgstr "``fill_zero()'': Set the memory of tensor to all 0"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:20
msgid "``share_memory_with()``: 可以和其他 **LiteTensor** 的共享内存"
msgstr "``share_memory_with()'': can share memory with other **LiteTensor**"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:21
msgid "``copy_from()``: 从其他 **LiteTensor** 中copy数据到自身内存中"
msgstr "``copy_from()'': copy data from other **LiteTensor** to its own memory"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:22
msgid "``reshape()``: 改变该 **LiteTensor** 的shape，内存数据保持不变"
msgstr "``reshape()'': Change the shape of the **LiteTensor**, and the memory data remains unchanged"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:23
msgid "``slice()``: 对该 **LiteTensor** 中的数据进行切片，需要分别指定每一维切片的start，end，和step。"
msgstr "``slice()'': To slice the data in the **LiteTensor**, you need to specify the start, end, and step of each dimension slice respectively."

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:24
msgid "``set_data_by_share()``: 调用之后使得该 **LiteTensor** 中的内存共享自输入的array的内存，输入的array必须是numpy的ndarray，并且tensor在CPU上"
msgstr "``set_data_by_share()'': After the call, the memory in the **LiteTensor** is shared with the memory of the input array, the input array must be a numpy ndarray, and the tensor is on the CPU"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:25
msgid "``set_data_by_copy()``: 该 **LiteTensor** 将会从输入的data中copy数据，data可以是list和numpy的ndarray，需要保证data的数据量不超过tensor的容量，tensor在CPU上"
msgstr "``set_data_by_copy()'': The **LiteTensor** will copy the data from the input data. The data can be a list and numpy ndarray. It is necessary to ensure that the amount of data does not exceed the capacity of the tensor, and the tensor is on the CPU"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:26
msgid "``to_numpy()``: 将该 **LiteTensor** 中数据copy到numpy的array中，返回给用户，如果是非连续的 **LiteTensor** ，如slice出来的，将copy到连续的numpy array中，该接口主要数为了debug，有性能问题。"
msgstr "``to_numpy()'': Copy the data in the **LiteTensor** to the numpy array and return it to the user. If it is a non-continuous **LiteTensor**, such as sliced out, it will be copied to a continuous numpy array Among them, this interface is mainly used for debugging and has performance problems."

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:28
msgid "对 **LiteTensor** 赋值，请参考："
msgstr "Assign values to **LiteTensor**, please refer to："

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:68
msgid "让多个 **LiteTensor** 共享同一块内存数据，请参考："
msgstr "Let multiple **LiteTensor** share the same memory data, please refer to："

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:106
msgid "LiteNetwork"
msgstr "LiteNetwork"

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:108
msgid "**LiteNetwork** 主要为用户提供模型载入，运行等功能。"
msgstr "**LiteNetwork** mainly provides users with functions such as model loading and running."

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:110
msgid "以CPU为后端的模型载入、运行，请参考："
msgstr "Load and run the model with CPU as the backend, please refer to："

#: ../../source/user-guide/deployment/lite/pylite-advanced.rst:187
msgid "以CUDA为后端，使用device内存作为模型输入，需要在构造network候配置config和IO信息。请参考："
msgstr "With CUDA as the backend and device memory as model input, it is necessary to configure config and IO information when constructing the network. Please refer to："

