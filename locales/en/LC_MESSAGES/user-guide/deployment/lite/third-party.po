msgid ""
msgstr ""
"Project-Id-Version: megengine-documentation\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-11-08 21:51+0800\n"
"PO-Revision-Date: 2023-04-20 08:44\n"
"Last-Translator: \n"
"Language-Team: English\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: megengine-documentation\n"
"X-Crowdin-Project-ID: 582157\n"
"X-Crowdin-Language: en\n"
"X-Crowdin-File: /dev/locales/en/LC_MESSAGES/user-guide/deployment/lite/third-party.po\n"
"X-Crowdin-File-ID: 1357\n"
"Language: en_US\n"

#: ../../source/user-guide/deployment/lite/third-party.rst:5
msgid "MegEngine Lite 第三方硬件支持"
msgstr "MegEngine Lite third-party hardware support"

#: ../../source/user-guide/deployment/lite/third-party.rst:7
msgid "MdegEngine Lite 的设计为方便地支持第三方硬件做了考量。"
msgstr "MdegEngine Lite is designed to conveniently support third-party hardware."

#: ../../source/user-guide/deployment/lite/third-party.rst:9
msgid "目前，我们以 rknn 设备（rk3568）为范例做了支持。"
msgstr "Currently, we use the rknn device (rk3568) as an example to support it."

#: ../../source/user-guide/deployment/lite/third-party.rst:12
msgid "编译"
msgstr "Compile"

#: ../../source/user-guide/deployment/lite/third-party.rst:14
msgid "目前 Lite 有两个后端：``mge`` 和 ``rknn`` 。"
msgstr "Currently Lite has two backends：``mge`` and ``rknn``."

#: ../../source/user-guide/deployment/lite/third-party.rst:16
msgid "可以同时编译两个后端，也可以只编译一个后端；"
msgstr "You can compile two backends at the same time, or you can compile only one backend;"

#: ../../source/user-guide/deployment/lite/third-party.rst:17
msgid "因为需要依赖 rknn 的第三方动态库，所以目前编译出来的都是动态库;"
msgstr "Because it needs to rely on rknn's third-party dynamic library, all currently compiled are dynamic libraries;"

#: ../../source/user-guide/deployment/lite/third-party.rst:18
msgid "目前只支持编译 android 版本，包括 android arm64 和 android armv7."
msgstr "Currently only supports compiling android version, including android arm64 and android armv7."

#: ../../source/user-guide/deployment/lite/third-party.rst:21
msgid "使用"
msgstr "use"

#: ../../source/user-guide/deployment/lite/third-party.rst:23
msgid "下面主要介绍工程集成 rknn 时候使用 lite 的接口，基本推理调用流程为："
msgstr "The following mainly introduces the interface of lite when the project integrates rknn, the basic reasoning call flow is："

#: ../../source/user-guide/deployment/lite/third-party.rst:25
msgid "构造 network 并 load 数据"
msgstr "Construct network and load data"

#: ../../source/user-guide/deployment/lite/third-party.rst:26
msgid "获取模型的 input tensor"
msgstr "Get the input tensor of the model"

#: ../../source/user-guide/deployment/lite/third-party.rst:27
msgid "copy 数据到输入 tensor 中"
msgstr "Copy the data to the input tensor"

#: ../../source/user-guide/deployment/lite/third-party.rst:28
msgid "Inference"
msgstr ""

#: ../../source/user-guide/deployment/lite/third-party.rst:29
msgid "读取输出数据"
msgstr "Read output data"

#: ../../source/user-guide/deployment/lite/third-party.rst:65
msgid "rknn 中如果输入 tensor 的 format 和 data type 和模型 input 的数据不一样的时候， 可以对输入数据进行配置，rknn 内部自己转换为需要的数据格式。 主要在第 4 步 (forward) 之前，将目前输入数据的 format 和 data type 设置 tensor 中， 通过接口是 ``TensorUtils::set_tensor_information``"
msgstr "In rknn, if the format and data type of the input tensor are not the same as the data of the model input, you can configure the input data, and rknn will convert it to the required data format internally. Mainly before step 4 (forward), set the format and data type of the current input data in the tensor, and the interface is ``TensorUtils::set_tensor_information``"

#: ../../source/user-guide/deployment/lite/third-party.rst:85
msgid "其中 ``input info`` 中可以设置："
msgstr "：can be set in ``input info''"

#: ../../source/user-guide/deployment/lite/third-party.rst:87
msgid "``key:\"pass_through\"`` ,  类型: uint8_t,  输入数据是透传到 network 中"
msgstr "``key:\"pass_through\"``, type: uint8_t, the input data is transparently transmitted to the network"

#: ../../source/user-guide/deployment/lite/third-party.rst:88
msgid "``key:\"fmt\"`` ,  类型 (rknn_tensor_format)int,  非透传模式中，指明输入 tensor 的 format"
msgstr "``key:\"fmt\"``, type (rknn_tensor_format)int, in non-transparent mode, specify the format of the input tensor"

#: ../../source/user-guide/deployment/lite/third-party.rst:89
msgid "``key:\"type\"`` ,  类型 (rknn_tensor_type)int,  非透传模式下，指明输出 tensor 的 format"
msgstr "``key:\"type\"``, type (rknn_tensor_type)int, in non-transparent mode, specify the format of the output tensor"

#: ../../source/user-guide/deployment/lite/third-party.rst:91
msgid "输出内存预先申请主要是将输出内存提前申请，可以为用户外部申请的内存， 这样可以避免输出数据的copy，lite 中使用，依然是在第 4 步之前进行配置。"
msgstr "Pre-application for output memory is mainly to apply for output memory in advance, which can be externally applied for by the user, so as to avoid the copy of output data, which is used in lite, and it is still configured before step 4."

#: ../../source/user-guide/deployment/lite/third-party.rst:111
msgid "设置内存预先申请有两途径："
msgstr "There are two pre-set memory application ways："

#: ../../source/user-guide/deployment/lite/third-party.rst:113
msgid "通过对 output tensor 执行 reset 操作，调用 output tensor 的 reset 接口"
msgstr "By performing the reset operation on the output tensor, call the reset interface of the output tensor"

#: ../../source/user-guide/deployment/lite/third-party.rst:114
msgid "通过设置 output 的 information, \"is_prealloc\" 设置为 true"
msgstr "By setting the information of output, \"is_prealloc\" is set to true"

#: ../../source/user-guide/deployment/lite/third-party.rst:116
msgid "rknn 模型默认是量化的模型，正常情况下输出是int8，如果用户需要最终数据是 float， 可以通过在第 4 步 (forward) 之前，设置 output tensor 的数据类型为 float, 方法如下："
msgstr "The rknn model is a quantized model by default. Under normal circumstances, the output is int8. If the user needs the final data to be a float, you can set the data type of the output tensor to float before step 4 (forward), the method is as follows："

#: ../../source/user-guide/deployment/lite/third-party.rst:137
msgid "设置输出为 float 有两途径："
msgstr "There are two ways to set the output to float："

#: ../../source/user-guide/deployment/lite/third-party.rst:139
msgid "通过对 output tensor 执行 set_layout 接口，不改变 shape 的情况下，将 data type 设置为 LiteDataType::LITE_FLOAT"
msgstr "Set the data type to LiteDataType::LITE_FLOAT by executing the set_layout interface on the output tensor without changing the shape"

#: ../../source/user-guide/deployment/lite/third-party.rst:140
msgid "通过设置 output 的 information，\"want_float\" 这只为 true"
msgstr "By setting the information of output, \"want_float\" is only true"

#: ../../source/user-guide/deployment/lite/third-party.rst:142
msgid "output tensor 可以设置的 info 有："
msgstr "The info that can be set by output tensor is："

#: ../../source/user-guide/deployment/lite/third-party.rst:144
msgid "``key:\"want_float\"`` , 类型：uint8_t, 是否输出 tensor 转换为 float"
msgstr "``key:\"want_float\"``, type：uint8_t, whether to convert the output tensor to float"

#: ../../source/user-guide/deployment/lite/third-party.rst:145
msgid "``key:\"is_prealloc\"`` , 类型：uint8_t, 输出是否提前申请好"
msgstr "``key:\"is_prealloc\"``, type：uint8_t, whether the output is applied in advance"

