msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-04-19 16:51+0800\n"
"PO-Revision-Date: 2022-04-19 12:42\n"
"Last-Translator: \n"
"Language: en_US\n"
"Language-Team: English\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: en\n"
"X-Crowdin-File: /[MegEngine.Documentation] main/locales/en/LC_MESSAGES/user-guide/model-development/serialization/index.po\n"
"X-Crowdin-File-ID: 8175\n"

#: ../../source/user-guide/model-development/serialization/index.rst:5
msgid "保存与加载模型（S&L）"
msgstr "Save and Load Models (S&L)"

#: ../../source/user-guide/model-development/serialization/index.rst:7
msgid "在模型开发的过程中，我们经常会遇到需要保存（Save）和加载（Load）模型的情况，例如："
msgstr "In the process of model development, we often encounter situations where we need to save (Save) and load (Load) models, such as："

#: ../../source/user-guide/model-development/serialization/index.rst:9
msgid "为了避免不可抗力导致的训练中断，需要养成模型每训练一定时期（Epoch）就进行保存的好习惯；"
msgstr "In order to avoid training interruption caused by force majeure, it is necessary to develop the good habit of saving the model every certain period of training (Epoch);"

#: ../../source/user-guide/model-development/serialization/index.rst:10
msgid "同时如果训练时间过长，可能会导致模型在训练数据集上过拟合，因此需要保存多个检查点，取最优结果；"
msgstr "At the same time, if the training time is too long, the model may be overfitted on the training data set, so it is necessary to save multiple checkpoints and obtain the optimal result;"

#: ../../source/user-guide/model-development/serialization/index.rst:11
msgid "某些情况下，我们需要加载预训练模型的参数和其它必需信息，恢复训练或进行微调..."
msgstr "In some cases, we need to load the parameters and other required information of the pre-trained model, resume training or fine-tune..."

#: ../../source/user-guide/model-development/serialization/index.rst:13
msgid "在 MegEngine 中对 Python 自带的 :mod:`pickle` 模块进行了封装， 来实现对 Python 对象结构（如 Module 对象）的二进制序列化和反序列化。 其中需要被我们熟知的核心接口为 :func:`megengine.save` 和 :func:`megengine.load`:"
msgstr "The :mod:`pickle` module that comes with Python is encapsulated in MegEngine to implement binary serialization and deserialization of Python object structures (such as Module objects). The core interfaces that need to be known to us are :func:`megengine.save` and :func:`megengine.load`:"

#: ../../source/user-guide/model-development/serialization/index.rst:20
msgid "上述语法非常简明直观地对整个 ``model`` 模型进行了保存和加载，但这并不是推荐做法。 更加推荐的做法是保存和加载 ``state_dict`` 对象，或使用检查点（Checkpoint）技术。 接下来将对上面的内容做更加具体的解释，并提供一些情景下保存和加载模型的最佳实践。 你可以略过已经熟悉的概念，直接跳转到所需的用例代码展示。"
msgstr "The above syntax is very concise and intuitive to save and load the entire ``model`` model, but it is not recommended. A more recommended approach is to save and load ``state_dict`` objects, or use checkpointing techniques. The following will explain the above in more detail, and provide some best practices for saving and loading models in some scenarios. You can skip the concepts you are already familiar with and jump directly to the desired use case code demonstration."

#: ../../source/user-guide/model-development/serialization/index.rst:27
msgid ":ref:`save-load-entire-model`"
msgstr ":ref:`save-load-entire-model`"

#: ../../source/user-guide/model-development/serialization/index.rst:28
msgid "任何情况下都不推荐 ❌"
msgstr "Not recommended under any circumstances ❌"

#: ../../source/user-guide/model-development/serialization/index.rst:29
msgid ":ref:`save-load-model-state-dict`"
msgstr ":ref:`save-load-model-state-dict`"

#: ../../source/user-guide/model-development/serialization/index.rst:30
msgid "适用于推理 ✅ 不满足恢复训练要求 😅"
msgstr "Suitable for inference ✅ Does not meet recovery training requirements 😅"

#: ../../source/user-guide/model-development/serialization/index.rst:31
msgid ":ref:`save-load-checkpoint`"
msgstr ":ref:`save-load-checkpoint`"

#: ../../source/user-guide/model-development/serialization/index.rst:32
msgid "适用于推理或恢复训练 💡"
msgstr "Suitable for inference or recovery training 💡"

#: ../../source/user-guide/model-development/serialization/index.rst:33
msgid ":ref:`dump-traced-model` （Dump）"
msgstr ":ref:`dump-traced-model` (Dump)"

#: ../../source/user-guide/model-development/serialization/index.rst:34
msgid "适用于推理，且追求高性能部署 🚀"
msgstr "It is suitable for inference and pursues high-performance deployment 🚀"

#: ../../source/user-guide/model-development/serialization/index.rst:38
msgid "使用 ``pickle`` 模块时，相应术语也叫做封存（pickling）和解封（unpickling）。"
msgstr "When using the ``pickle`` module, the corresponding terms are also called pickling and unpickling."

#: ../../source/user-guide/model-development/serialization/index.rst:40
msgid "pickle 模块与协议的兼容"
msgstr "The pickle module is compatible with the protocol"

#: ../../source/user-guide/model-development/serialization/index.rst:43
msgid "由于不同版本的 Python 之间 ``pickle`` 模块使用的 `数据流格式 <https://docs.python.org/3/library/pickle.html#data-stream-format>`_ 协议可能不同， 因此可能会出现高版本 Python 保存的 MegEngine 模型在低版本 Python 无法加载的情况。这里提供两种解决思路："
msgstr "Since the `data stream format <https://docs.python.org/3/library/pickle.html#data-stream-format>`_ protocol used by the ``pickle`` module may be different between different versions of Python, the MegEngine model saved in a higher version of Python may not be loaded in a lower version of Python. There are two solutions here："

#: ../../source/user-guide/model-development/serialization/index.rst:48
msgid "在调用 :func:`megengine.save` 时，通过参数 ``pickle_protocol`` 指定兼容性较强的版本（比如第 4 版）;"
msgstr "When calling :func:`megengine.save`, specify a more compatible version (such as version 4) through the parameter ``pickle_protocol``;"

#: ../../source/user-guide/model-development/serialization/index.rst:49
msgid "接口 :func:`megengine.save` 和 :func:`megengine.load` 都支持传入 ``pickle_module`` 参数， 从而使用指定的 ``pickle`` 模块，比如安装并使用 `pickle5 <https://pypi.org/project/pickle5/>`_ 来代替 Python 内置的 ``pickle`` 模块："
msgstr "Interfaces :func:`megengine.save` and :func:`megengine.load` both support passing in the ``pickle_module`` parameter to use the specified ``pickle`` module, such as installing and using `pickle5 <https://pypi.org/project/pickle5/>`_ instead of the built-in Python ``pickle`` module："

#: ../../source/user-guide/model-development/serialization/index.rst:55
msgid "pickle 模块并不安全！"
msgstr "The pickle module is not safe!"

#: ../../source/user-guide/model-development/serialization/index.rst:58
msgid "不坏好意的人可以通过构建恶意的 ``pickle`` 数据来在解封时执行任意代码；"
msgstr "A well-meaning person can execute arbitrary code when unpacked by constructing malicious ``pickle`` data;"

#: ../../source/user-guide/model-development/serialization/index.rst:59
msgid "因此绝对不要对不信任来源的数据和可能被篡改过的数据进行解封。"
msgstr "Therefore, never unblock data from untrusted sources and data that may have been tampered with."

#: ../../source/user-guide/model-development/serialization/index.rst:62
msgid "下面是我们用于举例的 ``ConvNet`` 模型："
msgstr "Below is the ``ConvNet`` model we used for example："

#: ../../source/user-guide/model-development/serialization/index.rst:96
msgid "保存/加载整个模型"
msgstr "save/load entire model"

#: ../../source/user-guide/model-development/serialization/index.rst:98
#: ../../source/user-guide/model-development/serialization/index.rst:123
#: ../../source/user-guide/model-development/serialization/index.rst:190
msgid "保存："
msgstr "save："

#: ../../source/user-guide/model-development/serialization/index.rst:102
#: ../../source/user-guide/model-development/serialization/index.rst:127
#: ../../source/user-guide/model-development/serialization/index.rst:202
msgid "加载："
msgstr "load："

#: ../../source/user-guide/model-development/serialization/index.rst:109
msgid "我们不推荐使用这种方法的原因在于 ``pickle`` 本身的局限性：对于特定的类，如用户自己设计的一个 ``ConvNet`` 模型类， ``pickle`` 在保存该模型时不会序列化模型类本身，而是会将该类与包含其定义的源码的路径绑定，如 ``project/model.py``. 在加载模型时， ``pickle`` 需要用到此路径。因此如果在后续的开发过程中，你对项目进行了重构 （比如将 ``model.py`` 进行了重命名），将导致执行模型加载的步骤时失败。"
msgstr "The reason we do not recommend using this method is due to the limitations of ``：itself. For a specific class, such as a ``ConvNet`` model class designed by the user, ``pickle`` does not save the model. will serialize the model class itself, but will instead bind the class to the path containing the source code for its definition, such as ``project/model.py``. This path is required by ``pickle`` when loading the model . So if you refactor the project later in the development process (for example, rename ``model.py``), it will cause the model loading step to fail."

#: ../../source/user-guide/model-development/serialization/index.rst:116
msgid "如果你依旧使用这种方法加载模型并尝试进行推理，记得先调用 ``model.eval()`` 切换到评估模式。"
msgstr "If you still use this method to load the model and try to infer, remember to switch to evaluation mode by calling ``model.eval()`` first."

#: ../../source/user-guide/model-development/serialization/index.rst:121
msgid "保存/加载模型状态字典"
msgstr "save/load model state dictionary"

#: ../../source/user-guide/model-development/serialization/index.rst:133
msgid "当保存一个仅用作推理的模型时，必须进行的处理是保存模型中学得的参数（Learned parameters）。 相较于保存整个模型，更加推荐保存模型的状态字典 ``state_dict``, 在后续恢复模型时将更加灵活。"
msgstr "When saving a model for inference only, the necessary processing is to save the learned parameters of the model. Rather than saving the entire model, it is recommended to save the model's state dictionary ``state_dict``, which will be more flexible when restoring the model later."

#: ../../source/user-guide/model-development/serialization/index.rst:138
msgid "相较于加载整个模型的做法，此时 ``megengine.load()`` 得到的结果是一个状态字典对象， 因此还需要通过 ``model.load_state_dict()`` 方法进一步将状态字典加载到模型中， 不能够使用 ``model = megengine.load(PATH)``; 另一种常见的错误用法是直接 ``model.load_state_dict(PATH)``, 注意必须先通过 ``megengine.load()`` 反序列化得到状态字典，再传递给 ``model.load_state_dict()`` 方法；"
msgstr "Compared to loading the entire model, the result obtained by ``megengine.load()`` is a state dictionary object, so it is necessary to further load the state dictionary into the model through the ``model.load_state_dict()`` method. ``model = megengine.load(PATH)`` cannot be used in ` Deserialize the state dictionary and pass it to the ``model.load_state_dict()`` method;"

#: ../../source/user-guide/model-development/serialization/index.rst:142
msgid "加载状态字典成功后，记得调用 ``model.eval()`` 将模型切换到评估模式。"
msgstr "After loading the state dictionary successfully, remember to call ``model.eval()`` to switch the model to evaluation mode."

#: ../../source/user-guide/model-development/serialization/index.rst:146
msgid "通常我们约定使用 ``.pkl`` 文件扩展名保存模型，如 ``mge_checkpoint_xxx.pkl`` 形式。"
msgstr ""

#: ../../source/user-guide/model-development/serialization/index.rst:148
msgid "注意 ``.pkl`` 与 ``.mge`` 文件的区别"
msgstr ""

#: ../../source/user-guide/model-development/serialization/index.rst:151
msgid "``.mge`` 文件通常是 MegEngine 模型经过 :ref:`dump` 得到的文件，用于推理部署。"
msgstr ""

#: ../../source/user-guide/model-development/serialization/index.rst:154
msgid "什么是状态字典"
msgstr "what is a state dictionary"

#: ../../source/user-guide/model-development/serialization/index.rst:156
msgid "由于使用 ``pickle`` 直接 :ref:`save-load-entire-model` 时存在受到路径影响的局限性， 我们则需要考虑使用原生的 Python 数据结构来记录模型内部的状态信息，方便进行序列化和反序列化。 在 :ref:`module-design` 中，我们提到了每个 Module 有一个状态字典成员， 记录着模型内部的 Tensor 信息（即 :ref:`parameter-and-buffer` ）："
msgstr "Due to the limitation of path impact when using ``pickle`` to directly :ref:`save-load-entire-model`, we need to consider using the native Python data structure to record the state information inside the model, which is convenient for serialization and Deserialize. In :ref:`module-design`, we mentioned that each Module has a state dictionary member, which records the Tensor information inside the model (ie :ref:`parameter-and-buffer`)："

#: ../../source/user-guide/model-development/serialization/index.rst:172
msgid "状态字典是一个简单的 Python 字典对象，因此可以借助 ``pickle`` 轻松地保存和加载。"
msgstr "The state dictionary is a simple Python dictionary object, so it can be easily saved and loaded with the help of ``pickle``."

#: ../../source/user-guide/model-development/serialization/index.rst:177
msgid "每个优化器 ``Optimzer`` 也有一个状态字典，其中包含有关优化器状态的信息，以及使用的超参数； 如果后续有恢复模型并且继续训练的需求，仅保存模型的状态字典是不行的 —— 我们同时还需要保存优化器的状态字典等信息，即下面提到的 “检查点” 技术。"
msgstr "Each optimizer ``Optimzer`` also has a state dictionary, which contains information about the state of the optimizer, and the hyperparameters used; if there is a subsequent need to restore the model and continue training, just saving the model's state dictionary is not enough — — We also need to save information such as the optimizer's state dictionary, which is the \"checkpoint\" technique mentioned below."

#: ../../source/user-guide/model-development/serialization/index.rst:183
msgid "关于状态字典的进一步解释： :ref:`module-state-dict` / :ref:`optimizer-state-dict`"
msgstr "Further explanation about state dictionary： :ref:`module-state-dict` / :ref:`optimizer-state-dict`"

#: ../../source/user-guide/model-development/serialization/index.rst:188
msgid "保存/加载检查点"
msgstr "save/load checkpoint"

#: ../../source/user-guide/model-development/serialization/index.rst:219
msgid "保存检查点是为了能够恢复到和训练时一致的状态： 需要恢复的不仅仅是 :ref:`module-state-dict` ，:ref:`optimizer-state-dict`. 根据实际需求，还可以记录训练时达到的 ``epoch`` 以及最新的 ``loss`` 信息。"
msgstr "The purpose of saving checkpoints is to be able to restore to the same state as the training time： need to restore not only :ref:`module-state-dict` ,:ref:`optimizer-state-dict`. According to actual needs, you can also record the training achieved ``epoch`` and the latest ``loss`` information."

#: ../../source/user-guide/model-development/serialization/index.rst:222
msgid "加载检查点后，根据是希望继续训练，还是用作推理来设置模型为训练或评估模式。"
msgstr "After the checkpoint is loaded, set the model to train or evaluation mode, depending on whether you want to continue training or use it for inference."

#: ../../source/user-guide/model-development/serialization/index.rst:226
msgid "相较于仅保存模型的状态字典，保存完整检查点会占据比较多的硬盘空间。 因此如果你十分确定以后只需要进行模型推理时，可以不必保存检查点。 亦或者设定不同的保存频率，例如每 10 个 Epochs 保存一次状态字典， 每 100 个 Epochs 保存一次完整的检查点，这取决于你的实际需求。"
msgstr "Saving a full checkpoint will take up more disk space than just saving the model's state dictionary. So you don't have to save checkpoints if you're pretty sure you only need to do model inference in the future. Or set a different saving frequency, such as saving a state dictionary every 10 Epochs, and saving a full checkpoint every 100 Epochs, depending on your actual needs."

#: ../../source/user-guide/model-development/serialization/index.rst:233
msgid "参考官方 ResNet 模型中如何保存和加载检查点："
msgstr "Refer to how to save and load checkpoints in the official ResNet model："

#: ../../source/user-guide/model-development/serialization/index.rst:235
msgid ":models:`official/vision/classification/resnet`"
msgstr ":models:`official/vision/classification/resnet`"

#: ../../source/user-guide/model-development/serialization/index.rst:237
msgid "在 ``train/test/inference.py`` 可找到相关接口。"
msgstr "The relevant interface can be found in ``train/test/inference.py``."

#: ../../source/user-guide/model-development/serialization/index.rst:242
msgid "导出静态图模型"
msgstr "Export static graph models"

#: ../../source/user-guide/model-development/serialization/index.rst:244
msgid "为了将最终训练好的模型部署到生产环境，模型开发的最后一步需要导出静态图模型："
msgstr "In order to deploy the final trained model to the production environment, the last step of model development requires exporting a static graph："

#: ../../source/user-guide/model-development/serialization/index.rst:267
msgid "更加具体的解释请参考： :ref:`dump` 。"
msgstr "See： :ref:`dump` for a more specific explanation."

#~ msgid "模型（参数）的保存与加载"
#~ msgstr "Saving and loading of models (parameters)"

#~ msgid "内容正在建设中..."
#~ msgstr "The content is under construction..."

#~ msgid "通常我们约定使用 ``.mge`` / ``.pkl`` 文件扩展名保存模型。"
#~ msgstr "Usually we use the ``.mge`` / ``.pkl`` file extension to save models."

