msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-12-28 09:14+0000\n"
"PO-Revision-Date: 2021-12-29 01:33\n"
"Last-Translator: \n"
"Language: zh_TW\n"
"Language-Team: Chinese Traditional\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-TW\n"
"X-Crowdin-File: /[MegEngine.Documentation] main/locales/zh_CN/LC_MESSAGES/reference/api/megengine.autodiff.Function.po\n"
"X-Crowdin-File-ID: 6580\n"

#: ../../source/reference/api/megengine.autodiff.Function.rst:5
msgid "Function"
msgstr "crwdns88687:0crwdne88687:0"

#: megengine.core.autodiff.grad.Function:1 of
msgid "Defines a block of operations with customizable differentiation."
msgstr "crwdns61440:0crwdne61440:0"

#: megengine.core.autodiff.grad.Function:3 of
msgid "The computation should be defined in ``forward`` method, with gradient computation defined in ``backward`` method."
msgstr "crwdns61442:0crwdne61442:0"

#: megengine.core.autodiff.grad.Function:6 of
msgid "Each instance of ``Function`` should be used only once during forwardding."
msgstr "crwdns61444:0crwdne61444:0"

#: megengine.core.autodiff.grad.Function:9 of
msgid "实际案例"
msgstr "crwdns68419:0crwdne68419:0"

#: megengine.core.autodiff.grad.Function.backward:1 of
msgid "Compute the gradient of the forward function. It must be overriden by all subclasses."
msgstr "crwdns88689:0crwdne88689:0"

#: megengine.core.autodiff.grad.Function.backward
#: megengine.core.autodiff.grad.Function.forward of
msgid "参数"
msgstr "crwdns88691:0crwdne88691:0"

#: megengine.core.autodiff.grad.Function.backward:3 of
msgid "gradients of outputs that are returned by :meth:`forward`."
msgstr "crwdns88693:0:meth:crwdne88693:0"

#: megengine.core.autodiff.grad.Function.backward:7 of
msgid "In case when some tensors of outputs are not related to loss function, the corresponding values in ``output_grads`` would be ``None``."
msgstr "crwdns88695:0crwdne88695:0"

#: megengine.core.autodiff.grad.Function.backward:9 of
msgid "This method should return a tuple which containing the gradients of all inputs, in the same order as the ``inputs`` argument of :meth:`forward` . A ``Tensor`` could be returned instead if there is only one input. If users want to stop the propagation of some gradients, the corresponding returned values should be set ``None`` ."
msgstr "crwdns88697:0:meth:crwdne88697:0"

#: megengine.core.autodiff.grad.Function.forward:1 of
msgid "Applies operations to ``inputs`` and returns results. It must be overriden by all subclasses."
msgstr "crwdns88699:0crwdne88699:0"

#: megengine.core.autodiff.grad.Function.forward:3 of
msgid "input tensors."
msgstr "crwdns88701:0crwdne88701:0"

#: megengine.core.autodiff.grad.Function.forward of
msgid "返回"
msgstr "crwdns88703:0crwdne88703:0"

#: megengine.core.autodiff.grad.Function.forward:5 of
msgid "a tuple of Tensor or a single Tensor."
msgstr "crwdns88705:0crwdne88705:0"

#: megengine.core.autodiff.grad.Function.forward:9 of
msgid "This method should return a tuple of Tensor or a single Tensor representing the output of the function."
msgstr "crwdns88707:0crwdne88707:0"

#: megengine.core.autodiff.grad.Function.forward:11 of
msgid "positional arguments should all be Tensor"
msgstr "crwdns88709:0crwdne88709:0"

#~ msgid "Examples:"
#~ msgstr "例如："

#~ msgid "megengine.autodiff.Function"
#~ msgstr ""

#~ msgid "Attributes"
#~ msgstr "属性"

#~ msgid ":obj:`scope <megengine.autodiff.Function.scope>`\\"
#~ msgstr ""

#~ msgid "Methods"
#~ msgstr "方法"

#~ msgid ""
#~ ":obj:`backward <megengine.autodiff.Function.backward>`\\ "
#~ "\\(\\*output\\_grads\\)"
#~ msgstr ""

#~ msgid "Compute the gradient of the forward function."
#~ msgstr ""

#~ msgid ""
#~ ":obj:`forward <megengine.autodiff.Function.forward>`\\ "
#~ "\\(\\*args\\, \\*\\*kwargs\\)"
#~ msgstr ""

#~ msgid "Applies operations to ``inputs`` and returns results."
#~ msgstr ""

