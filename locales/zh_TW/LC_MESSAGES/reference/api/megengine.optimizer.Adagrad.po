msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-15 19:44+0800\n"
"PO-Revision-Date: 2021-04-20 08:57\n"
"Last-Translator: \n"
"Language-Team: Chinese Traditional\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.4.0\n"
"X-Crowdin-File: /[MegEngine.Documentation] main/locales/zh_CN/LC_MESSAGES/reference/api/megengine.optimizer.Adagrad.po\n"
"X-Crowdin-File-ID: 2554\n"
"X-Crowdin-Language: zh-TW\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:2
msgid "megengine.optimizer.Adagrad"
msgstr "crwdns39384:0crwdne39384:0"

#: megengine.optimizer.adagrad.Adagrad:1 of
msgid "基类：:class:`megengine.optimizer.optimizer.Optimizer`"
msgstr "crwdns39386:0:class:crwdne39386:0"

#: megengine.optimizer.adagrad.Adagrad:1 of
msgid "Implements Adagrad algorithm."
msgstr "crwdns39388:0crwdne39388:0"

#: megengine.optimizer.adagrad.Adagrad:3 of
msgid "It has been proposed in `\"Adaptive Subgradient Methods for Online Learning and Stochastic Optimization\" <http://jmlr.org/papers/v12/duchi11a.html>`_."
msgstr "crwdns39390:0crwdne39390:0"

#: megengine.optimizer.adagrad.Adagrad of
msgid "参数"
msgstr "crwdns39392:0crwdne39392:0"

#: megengine.optimizer.adagrad.Adagrad:7 of
msgid "iterable of parameters to optimize or dicts defining parameter groups."
msgstr "crwdns39394:0crwdne39394:0"

#: megengine.optimizer.adagrad.Adagrad:10 of
msgid "coefficient that scales delta before it is applied to the parameters. Default: 1e-2"
msgstr "crwdns39396:0crwdne39396:0"

#: megengine.optimizer.adagrad.Adagrad:13 of
msgid "learning rate decay. Default: 0"
msgstr "crwdns39398:0crwdne39398:0"

#: megengine.optimizer.adagrad.Adagrad:15 of
msgid "term added to the denominator to improve numerical stability. Default: 1e-10"
msgstr "crwdns39400:0crwdne39400:0"

#: megengine.optimizer.adagrad.Adagrad:18 of
msgid "weight decay (L2 penalty). Default: 0"
msgstr "crwdns39402:0crwdne39402:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:11
msgid "Methods"
msgstr "crwdns39404:0crwdne39404:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`__init__ <megengine.optimizer.Adagrad.__init__>`\\ \\(params\\[\\, lr\\, lr\\_decay\\, eps\\, ...\\]\\)"
msgstr "crwdns39406:0:obj:crwdnd39406:0__init__crwdnd39406:0__init__crwdne39406:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid "Initialize self."
msgstr "crwdns39408:0crwdne39408:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`add_param_group <megengine.optimizer.Adagrad.add_param_group>`\\ \\(param\\_group\\)"
msgstr "crwdns39410:0:obj:crwdne39410:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid "Add a param group to ``param_groups`` of the :class:`~megengine.optim.optimizer.Optimizer`."
msgstr "crwdns39412:0:class:crwdne39412:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`backward <megengine.optimizer.Adagrad.backward>`\\ \\(loss\\)"
msgstr "crwdns39414:0:obj:crwdne39414:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`bcast_param <megengine.optimizer.Adagrad.bcast_param>`\\ \\(\\)"
msgstr "crwdns39416:0:obj:crwdne39416:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`clear_grad <megengine.optimizer.Adagrad.clear_grad>`\\ \\(\\)"
msgstr "crwdns39418:0:obj:crwdne39418:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid "Set the grad attribute to None for all parameters."
msgstr "crwdns39420:0crwdne39420:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`load_state_dict <megengine.optimizer.Adagrad.load_state_dict>`\\ \\(state\\)"
msgstr "crwdns39422:0:obj:crwdne39422:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid "Loads the optimizer state."
msgstr "crwdns39424:0crwdne39424:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`state_dict <megengine.optimizer.Adagrad.state_dict>`\\ \\(\\[keep\\_var\\]\\)"
msgstr "crwdns39426:0:obj:crwdne39426:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid "Export the optimizer state."
msgstr "crwdns39428:0crwdne39428:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`step <megengine.optimizer.Adagrad.step>`\\ \\(\\)"
msgstr "crwdns39430:0:obj:crwdne39430:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid "Performs a single optimization step."
msgstr "crwdns39432:0crwdne39432:0"

#: ../../source/reference/api/megengine.optimizer.Adagrad.rst:22:<autosummary>:1
msgid ":obj:`zero_grad <megengine.optimizer.Adagrad.zero_grad>`\\ \\(\\)"
msgstr "crwdns39434:0:obj:crwdne39434:0"

