msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-04-25 01:18+0000\n"
"PO-Revision-Date: 2023-04-25 01:26\n"
"Last-Translator: \n"
"Language: zh_TW\n"
"Language-Team: Chinese Traditional\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-TW\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/api/megengine.functional.distributed.all_reduce_sum.po\n"
"X-Crowdin-File-ID: 9081\n"

#: ../../source/reference/api/megengine.functional.distributed.all_reduce_sum.rst:2
msgid "megengine.functional.distributed.all\\_reduce\\_sum"
msgstr "crwdns99927:0crwdne99927:0"

#: megengine.distributed.functional.all_reduce_sum:1 of
msgid "Reduce tensors with sum operation on each value across the specified group."
msgstr "crwdns99929:0crwdne99929:0"

#: megengine.distributed.functional.all_reduce_sum:3 of
msgid "``inp`` tensor must have identical shape in all processes across the group."
msgstr "crwdns99931:0crwdne99931:0"

#: megengine.distributed.functional.all_reduce_sum of
msgid "参数"
msgstr "crwdns99933:0crwdne99933:0"

#: megengine.distributed.functional.all_reduce_sum:6 of
msgid "tensor to be reduced."
msgstr "crwdns99935:0crwdne99935:0"

#: megengine.distributed.functional.all_reduce_sum of
msgid "关键字参数"
msgstr "crwdns121599:0crwdne121599:0"

#: megengine.distributed.functional.all_reduce_sum:9 of
msgid "the process group to work on. Default: ``WORLD``. ``WORLD`` group selects all processes available. list of process rank as parameter will create a new group to work on."
msgstr "crwdns99939:0crwdne99939:0"

#: megengine.distributed.functional.all_reduce_sum:13 of
msgid "the specific device to execute this operator. Default: ``None`` ``None`` will select the device of ``inp`` to execute. Specially, ``GPU`` device can assign a different stream to execute by adding a number right after a colon following the device name while ``:0`` denotes default stream of GPU, otherwise will use default stream."
msgstr "crwdns99941:0crwdne99941:0"

#: megengine.distributed.functional.all_reduce_sum of
msgid "返回类型"
msgstr "crwdns99943:0crwdne99943:0"

#: megengine.distributed.functional.all_reduce_sum:20 of
msgid ":py:class:`~megengine.tensor.Tensor`"
msgstr "crwdns99945:0crwdne99945:0"

#: megengine.distributed.functional.all_reduce_sum of
msgid "返回"
msgstr "crwdns99947:0crwdne99947:0"

#: megengine.distributed.functional.all_reduce_sum:21 of
msgid "A tensor with sum operation on each value across the group.  The shape of the output tensor must be the same as ``inp``, and the output tensor is going to be bitwise identical in all processes across the group."
msgstr "crwdns99949:0crwdne99949:0"

#: megengine.distributed.functional.all_reduce_sum:21 of
msgid "A tensor with sum operation on each value across the group."
msgstr "crwdns99951:0crwdne99951:0"

#: megengine.distributed.functional.all_reduce_sum:23 of
msgid "The shape of the output tensor must be the same as ``inp``, and the output tensor is going to be bitwise identical in all processes across the group."
msgstr "crwdns99953:0crwdne99953:0"

#: megengine.distributed.functional.all_reduce_sum:27 of
msgid "实际案例"
msgstr "crwdns99955:0crwdne99955:0"

#~ msgid "返回类型"
#~ msgstr "返回类型"

#~ msgid ":py:class:`~megengine.tensor.Tensor`"
#~ msgstr ":py:class:`~megengine.tensor.Tensor`"

#~ msgid "Create all_reduce_sum operator for collective communication."
#~ msgstr "创建用于聚合通信的 all_reduce_sum 算子。"

#~ msgid "communication group."
#~ msgstr "通信组。"

#~ msgid "execution device."
#~ msgstr "执行设备。"

#~ msgid "Reduce tensors across the specified group by sum."
#~ msgstr ""

#~ msgid "Input tensor."
#~ msgstr ""

#~ msgid ""
#~ "The process group to work on. The"
#~ " default group is WORLD which means"
#~ " all processes available. You can use"
#~ " a list of process ranks to "
#~ "create new group to work on it,"
#~ " e.g. [1, 3, 5]."
#~ msgstr ""

#~ msgid ""
#~ "The specific device to execute this "
#~ "operator. None default device means the"
#~ " device of inp will be used. "
#~ "Specify \"gpu0:1\" to execute this "
#~ "operator on diffrent cuda stream, 1 "
#~ "is stream id, and default stream "
#~ "id is 0."
#~ msgstr ""

#~ msgid "Result tensor."
#~ msgstr ""

#~ msgid "A tensor with sum operation on each value across the group."
#~ msgstr "对组中的的值进行求和操作所得到的张量。"

#~ msgid ""
#~ "The shape of the output tensor "
#~ "must be the same as ``inp``, and"
#~ " the output tensor is going to "
#~ "be bitwise identical in all processes"
#~ " across the group."
#~ msgstr "输出张量的形状必须与 ``inp`` 相同，并且输出张量在整个组的所有进程中都是完全相同的。"

#~ msgid "关键字参数"
#~ msgstr "关键字参数"

#~ msgid "Keyword Arguments"
#~ msgstr "关键字参数"

