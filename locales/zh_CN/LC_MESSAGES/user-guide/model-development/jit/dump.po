msgid ""
msgstr ""
"Project-Id-Version: megengine-documentation\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-04-19 16:51+0800\n"
"PO-Revision-Date: 2023-04-20 08:44\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: Chinese Simplified\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"X-Crowdin-Project: megengine-documentation\n"
"X-Crowdin-Project-ID: 582157\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /dev/locales/en/LC_MESSAGES/user-guide/model-development/jit/dump.po\n"
"X-Crowdin-File-ID: 1331\n"

#: ../../source/user-guide/model-development/jit/dump.rst:5
msgid "导出序列化模型文件（Dump）"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:9
msgid "序列化操作依赖于 :py:class:`~.jit.trace` 进行的 :ref:`将动态图转为静态图 <trace>` 操作；"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:10
msgid "与此同时，需要在 :py:class:`~.jit.trace` 中指定 ``capture_as_const = True`` 以将参数固化下来。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:12
msgid "考虑到推理部署需求，使用 :py:meth:`~.jit.trace.dump`, 即可将训练好的模型序列化到一个文件或文件对象中："
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:14
msgid "我们以使用 `ResNet50 <https://github.com/MegEngine/Models/tree/master/official/vision/classification/resnet>`_ 的预训练模型为例子，参考代码片段如下："
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:39
msgid "执行脚本，并完成模型转换后，我们就获得了 MegEngine C++ API 可识别的预训练模型文件 ``resnet50.mge`` ."
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:42
msgid "Dump 常用参数说明"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:44
msgid "使用 :meth:`~.jit.trace.dump` 时，可传入多个参数，其中最常用的有如下两个："
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:48
msgid "``arg_names``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:47
msgid "在序列化的时候统一设置模型输入 Tensor 的名字。由于不同的模型的差异，会导致输入 Tensor 的名字千差万别。 为了减少理解和使用难度，可使用此参数统一设置模型输入为诸如 ``arg_0``, ``arg_1``, ..."
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:53
msgid "``optimize_for_inference``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:51
msgid "训练出的模型往往在部署时不能发挥最优的性能， 而我们提供 ``optimize_for_inference`` 来保证序列化出的模型是经特定优化的。 详细的键值参数可见下方的 :ref:`optimieze-for-inference-options` ."
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:57
msgid "``optimize_for_inference`` 参数默认是 ``True`` ， 所以即使不给任何键值优化参数，仍然会做一些基础的优化操作， 这会导致序列化出来的模型相较之前的定义有细微的差别。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:62
msgid "Dump 带有测试数据的模型文件"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:64
msgid "使用 :meth:`~.jit.trace.dump` 时，设置如下参数："
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:75
msgid "``input_data``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:67
msgid "这是一个字符串列表，列表中的每个字符串都代表一组测试数据。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:69
msgid "字符串支持三种格式："
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:71
msgid "``var0:file0;var1:file1...`` 指定每个输入变量对应的文件名。文件可以是能被 opencv 加载的图片，也可以是 numpy.ndarray 的 pickle 文件。如果只有一个输入，输入的变量名可以省略。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:73
msgid "``var0:#rand(min, max, shape);var1:#rand...`` 指定每个输入变量的数据随机生成方式，形状是 ``shape``，值域是 ``[min, max)``。例如 ``rand(0, 255)``, ``rand(0, 255, 1, 3, 224, 224)`` 或 ``#rand(0, 255, 1, ...)`` （其中 ``...`` 表示 shape 的剩余部分）。如果形状没有被指定，就会使用网络中输入张量的形状。如果只有一个输入，输入的变量名可以省略。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:75
msgid "``@filename`` 指定输入文件名，文件中的每一行都是一个符合上面两种格式的字符串。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:77
msgid "更多相关的参数设置，请参考 :meth:`~.jit.trace.dump`."
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:82
msgid "推理优化选项表"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:85
msgid "``--enable-io16xc32``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:85
msgid "采用 float16 作为算子之间的数据传输类型，使用 float32 作为计算类型。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:88
msgid "``--enable-ioc16``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:88
msgid "采用 float16 作为算子之间的数据传输类型以及计算类型。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:91
msgid "``--enable-fuse-conv-bias-nonlinearity``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:91
msgid "是否融合 conv+bias+nonlinearity。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:94
msgid "``--enalbe-hwcd4``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:94
msgid "采用 hwcd4 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:97
msgid "``--enable-nchw88``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:97
msgid "采用 nchw88 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:100
msgid "``--enable-nchw44``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:100
msgid "采用 nchw44 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:103
msgid "``--enable-nchw44-dot``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:103
msgid "采用 nchw44_dot 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:106
msgid "``--enable-nchw32``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:106
msgid "采用 nchw32 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:109
msgid "``--enable-chwn4``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:109
msgid "采用 chwn4 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:112
msgid "``--enable-fuse-conv-bias-with-z``"
msgstr ""

#: ../../source/user-guide/model-development/jit/dump.rst:112
msgid "仅在使用 GPU 平台下可用，把 conv，bias (elemwise add)，z(elemwise add) 融合成一个算子。"
msgstr ""

