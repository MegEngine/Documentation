msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-15 19:44+0800\n"
"PO-Revision-Date: 2023-04-21 09:35\n"
"Last-Translator: \n"
"Language-Team: Chinese Simplified\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /dev/locales/en/LC_MESSAGES/user-guide/model-development/dump.po\n"
"X-Crowdin-File-ID: 9881\n"
"Language: zh_CN\n"

#: ../../source/user-guide/model-development/dump.rst:5
msgid "导出序列化模型文件（Dump）"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:9
msgid "序列化操作依赖于 :py:class:`~.jit.trace` 进行的 :ref:`将动态图转为静态图 <trace>` 操作；"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:10
msgid "与此同时，需要在 :py:class:`~.jit.trace` 中指定 ``capture_as_const = True`` 以将参数固化下来。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:12
msgid "考虑到推理部署需求，使用 :py:meth:`~.jit.trace.dump`, 即可将训练好的模型序列化到一个文件或文件对象中："
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:14
msgid "我们以 `ResNet50 <https://github.com/MegEngine/Models/tree/master/official/vision/classification/resnet>`_ 为例子，参考代码片段如下："
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:39
msgid "执行脚本，并完成模型转换后，我们就获得了 MegEngine C++ API 可识别的预训练模型文件 ``resnet50.mge`` ."
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:42
msgid "Dump 常用参数说明"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:44
msgid "使用 :meth:`~.jit.trace.dump` 时，可传入多个参数，其中最常用的有如下两个："
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:48
msgid "``arg_names``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:47
msgid "在序列化的时候统一设置模型输入 Tensor 的名字。由于不同的模型的差异，会导致输入 Tensor 的名字千差万别。 为了减少理解和使用难度，可使用此参数统一设置模型输入为诸如 ``arg_0``, ``arg_1``, ..."
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:53
msgid "``optimize_for_inference``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:51
msgid "训练出的模型往往在部署时不能发挥最优的性能， 而我们提供 ``optimize_for_inference`` 来保证序列化出的模型是经特定优化的。 详细的键值参数可见下方的 :ref:`optimieze-for-inference-options` ."
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:57
msgid "``optimize_for_inference`` 参数默认是 ``True`` ， 所以即使不给任何键值优化参数，仍然会做一些基础的优化操作， 这会导致序列化出来的模型相较之前的定义有细微的差别。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:64
msgid "推理优化选项表"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:67
msgid "``--enable-io16xc32``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:67
msgid "采用 float16 作为算子之间的数据传输类型，使用 float32 作为计算类型。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:70
msgid "``--enable-ioc16``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:70
msgid "采用 float16 作为算子之间的数据传输类型以及计算类型。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:73
msgid "``--enable-fuse-conv-bias-nonlinearity``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:73
msgid "是否融合 conv+bias+nonlinearity。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:76
msgid "``--enalbe-hwcd4``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:76
msgid "采用 hwcd4 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:79
msgid "``--enable-nchw88``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:79
msgid "采用 nchw88 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:82
msgid "``--enable-nchw44``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:82
msgid "采用 nchw44 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:85
msgid "``--enable-nchw44-dot``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:85
msgid "采用 nchw44_dot 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:88
msgid "``--enable-nchw32``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:88
msgid "采用 nchw32 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:91
msgid "``--enable-chwn4``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:91
msgid "采用 chwn4 数据布局。"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:94
msgid "``--enable-fuse-conv-bias-with-z``"
msgstr ""

#: ../../source/user-guide/model-development/dump.rst:94
msgid "仅在使用 GPU 平台下可用，把 conv，bias (elemwise add)，z(elemwise add) 融合成一个算子。"
msgstr ""

