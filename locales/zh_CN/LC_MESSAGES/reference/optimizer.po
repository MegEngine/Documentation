# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020-2021, The MegEngine Open Source Team
# This file is distributed under the same license as the MegEngine package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MegEngine 1.3.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-14 14:17+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"

#: ../../source/reference/optimizer.rst:6
msgid "优化器（Optimizer）"
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid ":obj:`Optimizer <megengine.optimizer.Optimizer>`"
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid "Base class for all optimizers."
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid ":obj:`Optimizer.step <megengine.optimizer.Optimizer.step>`"
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid "Performs a single optimization step."
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid ":obj:`Optimizer.clear_grad <megengine.optimizer.Optimizer.clear_grad>`"
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid "Set the grad attribute to None for all parameters."
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid ""
":obj:`Optimizer.add_param_group "
"<megengine.optimizer.Optimizer.add_param_group>`"
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid ""
"Add a param group to ``param_groups`` of the "
":class:`~megengine.optim.optimizer.Optimizer`."
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid ":obj:`Optimizer.state_dict <megengine.optimizer.Optimizer.state_dict>`"
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid "Export the optimizer state."
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid ""
":obj:`Optimizer.load_state_dict "
"<megengine.optimizer.Optimizer.load_state_dict>`"
msgstr ""

#: ../../source/reference/optimizer.rst:17:<autosummary>:1
msgid "Loads the optimizer state."
msgstr ""

#: ../../source/reference/optimizer.rst:19
msgid "常见优化器"
msgstr ""

#: ../../source/reference/optimizer.rst:28:<autosummary>:1
msgid ":obj:`SGD <megengine.optimizer.SGD>`"
msgstr ""

#: ../../source/reference/optimizer.rst:28:<autosummary>:1
msgid "Implements stochastic gradient descent."
msgstr ""

#: ../../source/reference/optimizer.rst:28:<autosummary>:1
msgid ":obj:`Adam <megengine.optimizer.Adam>`"
msgstr ""

#: ../../source/reference/optimizer.rst:28:<autosummary>:1
msgid ""
"Implements Adam algorithm proposed in `\"Adam: A Method for Stochastic "
"Optimization\" <https://arxiv.org/abs/1412.6980>`_."
msgstr ""

#: ../../source/reference/optimizer.rst:28:<autosummary>:1
msgid ":obj:`Adagrad <megengine.optimizer.Adagrad>`"
msgstr ""

#: ../../source/reference/optimizer.rst:28:<autosummary>:1
msgid "Implements Adagrad algorithm."
msgstr ""

#: ../../source/reference/optimizer.rst:28:<autosummary>:1
msgid ":obj:`Adadelta <megengine.optimizer.Adadelta>`"
msgstr ""

#: ../../source/reference/optimizer.rst:28:<autosummary>:1
msgid "Implements Adadelta algorithm."
msgstr ""

#: ../../source/reference/optimizer.rst:30
msgid "学习率调整"
msgstr ""

#: ../../source/reference/optimizer.rst:37:<autosummary>:1
msgid ":obj:`LRScheduler <megengine.optimizer.LRScheduler>`"
msgstr ""

#: ../../source/reference/optimizer.rst:37:<autosummary>:1
msgid "Base class for all learning rate based schedulers."
msgstr ""

#: ../../source/reference/optimizer.rst:37:<autosummary>:1
msgid ":obj:`MultiStepLR <megengine.optimizer.MultiStepLR>`"
msgstr ""

#: ../../source/reference/optimizer.rst:37:<autosummary>:1
msgid "Decays the learning rate of each parameter group by gamma once the"
msgstr ""

