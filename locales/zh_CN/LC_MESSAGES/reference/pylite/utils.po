msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-04-25 01:18+0000\n"
"PO-Revision-Date: 2023-05-11 10:51\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: Chinese Simplified\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/pylite/utils.po\n"
"X-Crowdin-File-ID: 10031\n"

#: ../../source/reference/pylite/utils.rst:6
msgid "megenginelite.utils"
msgstr ""

#: megenginelite.utils.TensorBatchCollector:1 of
msgid "A tensor utils is used to collect many single batch tensor to a multi batch size tensor, when the multi batch size tensor collect finish, the result tensor can be get and send to the model input for forwarding."
msgstr ""

#: megenginelite.utils.TensorBatchCollector:5 of
msgid "when collect single batch tensor, the single batch tensor is no need in the same device_type and device_id with the result tensor, however the dtype must match and the shape must match except the highest dimension."
msgstr ""

#: megenginelite.utils.TensorBatchCollector
#: megenginelite.utils.TensorBatchCollector.collect
#: megenginelite.utils.TensorBatchCollector.collect_by_ctypes
#: megenginelite.utils.TensorBatchCollector.collect_id
#: megenginelite.utils.TensorBatchCollector.free
#: megenginelite.utils.TensorBatchCollector.get_tensor_at of
msgid "参数"
msgstr ""

#: megenginelite.utils.TensorBatchCollector:9 of
msgid "the multi batch size tensor shape, After collection, the result tensor shape."
msgstr ""

#: megenginelite.utils.TensorBatchCollector:11 of
msgid "the datatype of the single batch tensor and the result tensor, default value is LiteDataType.LITE_INT8."
msgstr ""

#: megenginelite.utils.TensorBatchCollector:14 of
msgid "the target device type the result tensor will allocate, default value is LiteDeviceType.LITE_CUDA."
msgstr ""

#: megenginelite.utils.TensorBatchCollector:17 of
msgid "the device id the result tensor will allocate, default 0."
msgstr ""

#: megenginelite.utils.TensorBatchCollector:18 of
msgid "Whether the memory is pinned memory, refer to CUDA pinned memory, default False."
msgstr ""

#: megenginelite.utils.TensorBatchCollector:20 of
msgid "the result tensor, user can also create the multi batch size tensor and then create the TensorBatchColletor, if tensor is not None, all the member, such as shape, dtype, device_type, device_id, is_pinned_host will get from the tensor, if the tensor is None and the result tensor will create by the TensorBatchCollector, default is None."
msgstr ""

#: megenginelite.utils.TensorBatchCollector:30 of
msgid "when collect tensor, the single batch tensor or array shape must match the result tensor shape except the batch size dimension (the highest dimension)"
msgstr ""

#: megenginelite.utils.TensorBatchCollector:34 of
msgid "实际案例"
msgstr "实际案例"

#: megenginelite.utils.TensorBatchCollector.collect:1 of
msgid "Collect a single batch through an array and store the array data to an empty batch, the empty batch is the front batch id in free list."
msgstr ""

#: megenginelite.utils.TensorBatchCollector.collect:4
#: megenginelite.utils.TensorBatchCollector.collect_by_ctypes:5 of
msgid "an array maybe LiteTensor or numpy ndarray, the shape must match the result tensor shape except the highest dimension"
msgstr ""

#: megenginelite.utils.TensorBatchCollector.collect_by_ctypes:1 of
msgid "Collect a single batch through an ctypes memory buffer and store the ctypes memory data to an empty batch, the empty batch is the front batch id in free list."
msgstr ""

#: megenginelite.utils.TensorBatchCollector.collect_id:1 of
msgid "Collect a single batch through an array and store the array data to the specific batch_id."
msgstr ""

#: megenginelite.utils.TensorBatchCollector.collect_id:4 of
msgid "an array maybe LiteTensor or numpy ndarray, the shape of array must match the result tensor shape except the highest dimension."
msgstr ""

#: megenginelite.utils.TensorBatchCollector.collect_id:7 of
msgid "the batch id to store the array data to the result tensor, if the batch_id has already collected, a warning will generate."
msgstr ""

#: megenginelite.utils.TensorBatchCollector.free:1 of
msgid "free the batch ids in the indexes, after the batch id is freed, it can be collected again without warning."
msgstr ""

#: megenginelite.utils.TensorBatchCollector.free:4 of
msgid "a list of to be freed batch id"
msgstr ""

#: megenginelite.utils.TensorBatchCollector.get:1 of
msgid "After finish collection, get the result tensor"
msgstr ""

#: megenginelite.utils.TensorBatchCollector.get_tensor_at:1 of
msgid "get the tensor from the internal big tensor by the idx, make sure the idx is not freed, return the tensor"
msgstr ""

#: megenginelite.utils.TensorBatchCollector.get_tensor_at:4 of
msgid "the tensor index in the internal big tensor"
msgstr ""

#: megenginelite.utils.TensorBatchCollector.to_numpy:1 of
msgid "Convert the result tensor to a numpy ndarray"
msgstr ""

#~ msgid "this is a tensor utils to collect subtensor in batch continuous"
#~ msgstr ""

#~ msgid "collect with ctypes data input"
#~ msgstr ""

