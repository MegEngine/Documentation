# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020-2021, The MegEngine Open Source Team
# This file is distributed under the same license as the MegEngine package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: MegEngine 1.3.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-15 19:44+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"

#: ../../source/reference/api/megengine.optimizer.SGD.rst:2
msgid "megengine.optimizer.SGD"
msgstr ""

#: megengine.optimizer.sgd.SGD:1 of
msgid "基类：:class:`megengine.optimizer.optimizer.Optimizer`"
msgstr ""

#: megengine.optimizer.sgd.SGD:1 of
msgid "Implements stochastic gradient descent."
msgstr ""

#: megengine.optimizer.sgd.SGD:3 of
#, python-format
msgid ""
"Nesterov momentum is based on the formula from `\"On the importance of "
"initialization and momentum in deep learning\" "
"<http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf>`_ ."
msgstr ""

#: megengine.optimizer.sgd.SGD of
msgid "参数"
msgstr ""

#: megengine.optimizer.sgd.SGD:7 of
msgid "iterable of parameters to optimize or dicts defining parameter groups."
msgstr ""

#: megengine.optimizer.sgd.SGD:10 of
msgid "learning rate."
msgstr ""

#: megengine.optimizer.sgd.SGD:12 of
msgid "momentum factor. Default: 0.0"
msgstr ""

#: megengine.optimizer.sgd.SGD:14 of
msgid "weight decay (L2 penalty). Default: 0.0"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:11
msgid "Methods"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ""
":obj:`__init__ <megengine.optimizer.SGD.__init__>`\\ \\(params\\, "
"lr\\[\\, momentum\\, weight\\_decay\\]\\)"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid "Initialize self."
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ""
":obj:`add_param_group <megengine.optimizer.SGD.add_param_group>`\\ "
"\\(param\\_group\\)"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ""
"Add a param group to ``param_groups`` of the "
":class:`~megengine.optim.optimizer.Optimizer`."
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ":obj:`backward <megengine.optimizer.SGD.backward>`\\ \\(loss\\)"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ":obj:`bcast_param <megengine.optimizer.SGD.bcast_param>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ":obj:`clear_grad <megengine.optimizer.SGD.clear_grad>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid "Set the grad attribute to None for all parameters."
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ""
":obj:`load_state_dict <megengine.optimizer.SGD.load_state_dict>`\\ "
"\\(state\\)"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid "Loads the optimizer state."
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ""
":obj:`state_dict <megengine.optimizer.SGD.state_dict>`\\ "
"\\(\\[keep\\_var\\]\\)"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid "Export the optimizer state."
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ":obj:`step <megengine.optimizer.SGD.step>`\\ \\(\\)"
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid "Performs a single optimization step."
msgstr ""

#: ../../source/reference/api/megengine.optimizer.SGD.rst:22:<autosummary>:1
msgid ":obj:`zero_grad <megengine.optimizer.SGD.zero_grad>`\\ \\(\\)"
msgstr ""

