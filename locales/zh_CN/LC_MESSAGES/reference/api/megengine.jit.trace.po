msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-09-25 02:39+0000\n"
"PO-Revision-Date: 2023-09-25 06:42\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: Chinese Simplified\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/api/megengine.jit.trace.po\n"
"X-Crowdin-File-ID: 9457\n"

#: ../../source/reference/api/megengine.jit.trace.rst:5
msgid "trace"
msgstr "追踪"

#: megengine.jit.tracing.trace:1 of
msgid "Wraps a callable and provide:"
msgstr "包装一个可调用对象，并提供以下功能："

#: megengine.jit.tracing.trace:3 of
msgid "tracing via :meth:`.trace` and :meth:`.dump`"
msgstr "通过 :meth:`.trace` 和 :meth:`.dump` 实现追溯（tracing）"

#: megengine.jit.tracing.trace:4 of
msgid "accelerated evalutaion via :meth:`.__call__`"
msgstr "通过调用 :meth:`.__call__` 加速执行"

#: megengine.jit.tracing.trace megengine.jit.tracing.trace.dump of
msgid "参数"
msgstr "参数"

#: megengine.jit.tracing.trace:6 of
msgid "the function will be traced."
msgstr "将被追溯的函数。"

#: megengine.jit.tracing.trace:8 of
msgid "whether to apply symbolic execution for tracing. Default: False"
msgstr "是否为追溯使用符号执行。默认：False"

#: megengine.jit.tracing.trace:10 of
msgid "capture global vars or closures as const value. Default: False"
msgstr "将全局变量或闭包捕获为常值。默认：False"

#: megengine.jit.tracing.trace:12 of
msgid "if True, won't run even if call the function. Default: False"
msgstr "如果为True，则即使调用该函数也不会运行。默认：False"

#: megengine.jit.tracing.trace:14 of
msgid "configuration for sublinear memory optimization. If not None, it enables sublinear memory optimization with given setting."
msgstr "配置亚线性内存优化。如果不是None，则使用给定设置进行亚线性内存优化。"

#: megengine.jit.tracing.trace:18 of
msgid "configuration for DTR sublinear memory optimization. If not None, it enables DTR optimization with given setting."
msgstr "配置DTR亚线性内存优化。如果不是None，则启用给定设置的DTR优化。"

#: megengine.jit.tracing.trace:22 of
msgid "whether to profile compiled trace. Default: False"
msgstr "是否对编译好的函数追溯（trace）进行性能评估（profile）。默认：False"

#: megengine.jit.tracing.trace:25 of
msgid "optimization level for compiling trace. Default: 2"
msgstr "编译函数追溯（trace）的优化级别。 默认：2"

#: megengine.jit.tracing.trace:28 of
msgid "configuration for graph optimization. Default: None"
msgstr "图优化的配置。 默认：None"

#: megengine.jit.tracing.trace:31 of
msgid "whether to use symbolic shape for tracing. Default: True"
msgstr "是否为追溯使用符号形状。默认：True"

#: megengine.jit.tracing.trace:34 of
msgid "if True, will run python code of wrapped function on the first call, and run the compiled graph/function on subsequent calls. if False, will run python code every time. Default: False"
msgstr "如果为True，将在第一次调用时运行包装函数的python代码，并在后续调用时运行编译后的计算图/函数。如果为False，则每次都运行python代码。默认值: 假"

#: megengine.jit.tracing.trace:39 of
msgid "if True, will use imperative runtime to execute captured op seq. Default: False"
msgstr "如果为True，将使用命令式运行时执行捕获的op序列。默认值: 假"

#: megengine.jit.tracing.trace.dump:1 of
msgid "Serializes trace to file system."
msgstr "序列化被追溯 (trace) 的模型并保存到文件。"

#: megengine.jit.tracing.trace.dump:3 of
msgid "output file, could be file object or filename."
msgstr "输出文件，可以是文件对象或文件名"

#: megengine.jit.tracing.trace.dump:4 of
msgid "names of the input tensors in the traced function."
msgstr "被追溯（traced）函数的输入张量的名字。"

#: megengine.jit.tracing.trace.dump:5 of
msgid "names of the output tensors in the traced function, use the default name if not specified."
msgstr "被追溯（traced）函数的输出张量的名字，如果未指明则使用默认名字。"

#: megengine.jit.tracing.trace.dump:7 of
msgid "whether output is appended to ``file``. Only works when ``file`` is str."
msgstr "是否在 ``file`` 后追加输出。仅当 ``file`` 是文件名时可用。"

#: megengine.jit.tracing.trace.dump:10 of
msgid "level for keeping variable names:  * 0: none of the names are kept * 1: (default)keep names of output vars * 2: keep names of all (output and internal) vars"
msgstr "保留变量名的级别: \n\n"
"* 0: 不保留任何变量名\n\n"
"* 1(默认): 保留输出变量的名字\n\n"
"* 2: 保留所有变量 (包括输出和中间变量) 的名字"

#: megengine.jit.tracing.trace.dump:10 of
msgid "level for keeping variable names:"
msgstr "保存变量名的级别:"

#: megengine.jit.tracing.trace.dump:12 of
msgid "0: none of the names are kept"
msgstr "0: 不保留任何名称"

#: megengine.jit.tracing.trace.dump:13 of
msgid "1: (default)keep names of output vars"
msgstr "1:(默认)保留输出变量的名称"

#: megengine.jit.tracing.trace.dump:14 of
msgid "2: keep names of all (output and internal) vars"
msgstr "2: 保留所有(输出和内部) 变量的名称"

#: megengine.jit.tracing.trace.dump:16 of
msgid "whether to keep operator names."
msgstr "是否要保留算子的名字"

#: megengine.jit.tracing.trace.dump:18 of
msgid "whether to keep param names, so param values can be easily manipulated after loading model"
msgstr "是否要保留参数的名字，为了加载模型后可以简单地对参数做操作"

#: megengine.jit.tracing.trace.dump:21 of
msgid "whether to keep priority setting for operators"
msgstr "是否保留算子的优先级设置"

#: megengine.jit.tracing.trace.dump:23 of
msgid "whether to change the compute graph when dump, for model compatibility, some operators will convert to its compatible format in this version.  * if set False, some operators maybe convert to other operator for   compatibility, all operators will ensure compatibility. * if set True, no operator will change in the graph when dump."
msgstr "在导出的时候是否改变计算图，考虑到模型兼容性，一些算子在这个版本会转换为对应的兼容格式。* 如果设置为 False，为了兼容性一些算子可能会转换成其他算子，所有的算子都会确保兼容性。* 如果设置为 True，在导出的时候所有计算图中的算子都会改变。"

#: megengine.jit.tracing.trace.dump:23 of
msgid "whether to change the compute graph when dump, for model compatibility, some operators will convert to its compatible format in this version."
msgstr "在导出的时候是否改变计算图，考虑到模型兼容性，一些算子在这个版本会转换为对应的兼容格式。"

#: megengine.jit.tracing.trace.dump:27 of
msgid "if set False, some operators maybe convert to other operator for compatibility, all operators will ensure compatibility."
msgstr "如果设置为 False，为了兼容性一些算子可能会转换成其他算子，所有的算子都会确保兼容性。"

#: megengine.jit.tracing.trace.dump:29 of
msgid "if set True, no operator will change in the graph when dump."
msgstr "如果设置为 True，在导出的时候所有计算图中的算子都会改变。"

#: megengine.jit.tracing.trace.dump:30 of
msgid "a string for path or a file handler. if is not None, then the dump information for code strip would be written to ``strip_info_file``"
msgstr "路径地址或文件句柄。如果不为空，则导出的代码条信息会被写入``strip_info_file``中。"

#: megengine.jit.tracing.trace.dump:32 of
msgid "will be check when `strip_info_file` is not None. if set true, the information for code strip will be append to strip_info_file. if set false, will rewrite strip_info_file"
msgstr "当 `strip_info_file` 非空时会做检查。如果是真，代码条信息就会被添加到 `strip_info_file` 的尾部；如果是假，就会覆盖掉 `strip_info_file`."

#: megengine.jit.tracing.trace.dump:35 of
msgid "enbale optmizations, will skip all optimize options if this is False. Default: True"
msgstr "打开推理优化，如果是False则关闭所有优化选项。默认：True"

#: megengine.jit.tracing.trace.dump:38 of
msgid "any type object, which will be pickled to bytes."
msgstr "任何类型的对象，它将被 pickle 为字节。"

#: megengine.jit.tracing.trace.dump:40 of
msgid "whether to save metadata into output file."
msgstr "是否将元数据保存到输出文件中。"

#: megengine.jit.tracing.trace.dump:41 of
msgid "input test data and current network output would be used as groundtruth. The format is \"var0:file0;var1:file1...\" to specify data files for input vars. It can also be \"#rand(min,max,shape...)\" for generating random input data, for example, \"#rand(0,255)\", \"#rand(0,255,1,3,224,224)\" or \"#rand(0, 255, 1, ...)\" where `...` means the remaining part of the original shape. If the shape is not specified, the shape of corresponding input tensors in the network will be used. If there is only one input var, its name can be omitted. Each data file can either be an image which can be loaded by opencv, or a pickled numpy.ndarray. This option can be given multiple times to add multiple testcases. If you start the data with the letter @, the rest should be a filename, and each line in the file should be a single datum in the format described above. *NOTE* If `input_data` is not None, you can only use load-and-run to run the output file."
msgstr "输入测试数据和当前网络输出将作为groundtruth。 格式为 \"var0:file0;var1:file1...\" 以指定输入的数据文件。 也可以使用 \"#rand(min,max,shape...)\"，用于生成随机输入数据，例如，\"#rand(0,255)\", \"#rand(0,255,1,3,224,224)\" 或 \"#rand(0, 255, 1, ...)\" 其中 `...` 表示原始形状的剩余部分。 如果未指定形状，将使用网络中相应输入张量的形状。 如果只有一个输入，则可以省略其名称。 数据文件可以是能被 opencv 加载的图像，也可以是序列化的 numpy.ndarray。 可以多次使用此选项以添加多个测试用例。 如果您的数据以字母 @ 开头，其余的应该是一个文件名，并且文件中的每一行都应该是上述格式的单个数据。 *注意* 如果 `input_data` 不为 None，您只能使用 load-and-run 来运行输出文件。"

#: megengine.jit.tracing.trace.dump:53 of
msgid "how many times the input image is repeated. Useful when running benchmark for batch size other than one. Have no effect on randomly generated input data."
msgstr "输入图像重复次数。 在运行多批量大小的基准测试时很有用。 对随机生成的输入数据没有影响。"

#: megengine.jit.tracing.trace.dump:55 of
msgid "whether set verbose to False in assert_equal opr."
msgstr "在 assert_equal 中是否将 verbose 设置为 False。"

#: megengine.jit.tracing.trace.dump:56 of
msgid "whether insert assert_equal opr to check result; this option is useful for benchmarking."
msgstr "是否插入 assert_equal 检查结果； 此选项对于基准测试很有用。"

#: megengine.jit.tracing.trace.dump:58 of
msgid "max error for assert_equal check during runtime."
msgstr "运行时 assert_equal 检查的最大误差。"

#: megengine.jit.tracing.trace.dump:59 of
msgid "whether resize input image to fit input var shape."
msgstr "是否调整输入图像大小以适合输入 var 形状。"

#: megengine.jit.tracing.trace.dump:60 of
msgid "a python expression to transform the input data. Example: data / np.std(data)"
msgstr "用于转换输入数据的 python 表达式。 示例：data / np.std(data)"

#: megengine.jit.tracing.trace.dump:63 of
msgid "using different dump formats. the open source MegEngine defaults to the FBS_V2 format, there are two format FBS_V2 and FBS to choose, internal MegEngine have an other choice of internal proprietary formats"
msgstr "使用不同的导出格式。开源的 MegEngine 默认使用 FBS_V2 格式，有FBS_V2 和 FBS 两种 format 可供选择，内部 MegEngine 有其他内部专有格式选择"

#: megengine.jit.tracing.trace.dump:67 of
msgid "the model version of FBS_V2, begin with version 2, this works only when dump format is FBS_V2."
msgstr "FBS_V2 的模型版本，从版本 2 开始，仅当转储格式为 FBS_V2 时才有效。"

#: megengine.jit.tracing.trace.dump:70 of
msgid "the specified megbrain version which is less than 8.16 for model forward compatibility, only support \"8.14\" currently. Default: None."
msgstr ""

#: megengine.jit.tracing.trace.dump:72 of
msgid "Keyword Arguments:"
msgstr "关键字参数："

#: megengine.jit.tracing.trace.dump:74 of
msgid "enable_io16xc32 -- whether to use float16 for I/O between oprs and use float32 as internal computation precision. Note the output var would be changed to float16."
msgstr "enable_io16xc32 -- 是否使用 float16 进行 opr 之间的 I/O 并使用 float32 作为内部计算精度。 请注意，输出节点将更改为 float16。"

#: megengine.jit.tracing.trace.dump:78 of
msgid "enable_ioc16 -- whether to use float16 for both I/O and computation precision."
msgstr "enable_ioc16 -- 是否将 float16 用于 I/O 和计算精度。"

#: megengine.jit.tracing.trace.dump:81 of
msgid "enable_hwcd4 -- whether to use NHWCD4 data layout. This is faster on some OpenCL backend."
msgstr "enable_hwcd4 -- 是否使用 NHWCD4 数据布局。 在某些 OpenCL 后端上更快。"

#: megengine.jit.tracing.trace.dump:84 of
msgid "enable_nchw88 -- whether to use NCHW88 data layout, currently used in X86 AVX backend."
msgstr "enable_nchw88 -- 是否使用 NCHW88 数据布局，目前在 X86 AVX 后端使用。"

#: megengine.jit.tracing.trace.dump:87 of
msgid "enable_nchw44 -- whether to use NCHW44 data layout, currently used in arm backend."
msgstr "enable_nchw44 -- 是否使用 NCHW44 数据布局，目前在 arm 后端使用。"

#: megengine.jit.tracing.trace.dump:90 of
msgid "enable_nchw44_dot -- whether to use NCHW44_dot data layout, currently used in armv8.2+dotprod backend."
msgstr "enable_nchw44_dot -- 是否使用 NCHW44_dot 数据布局，目前在 armv8.2+dotprod 后端使用。"

#: megengine.jit.tracing.trace.dump:93 of
msgid "enable_nchw4 -- whether to use NCHW4 data layout, currently used in nvidia backend(based on cudnn)."
msgstr "enable_nchw4 -- 是否使用 NCHW4 数据布局，目前在 nvidia 后端使用（基于 cudnn）"

#: megengine.jit.tracing.trace.dump:96 of
msgid "enable_nchw32 -- whether to use NCHW32 data layout, currently used in nvidia backend with tensorcore(based on cudnn)."
msgstr "enable_nchw32 -- 是否使用 NCHW32 数据布局，目前在 nvidia 后端的 tensorcore 中使用（基于 cudnn）"

#: megengine.jit.tracing.trace.dump:99 of
msgid "enable_chwn4 -- whether to use CHWN4 data layout, currently used in nvidia backend with tensorcore."
msgstr "enable_chwn4 -- 是否使用 CHWN4 数据布局，目前在 nvidia 后端的 tensorcore 中使用。"

#: megengine.jit.tracing.trace.dump:102 of
msgid "enable_nchw64 -- whether to use NCHW64 data layout, used for fast int4 support on Nvidia GPU."
msgstr "enable_nchw64 -- 是否使用 NCHW64 数据布局，用于 Nvidia GPU 上的 int4 支持。"

#: megengine.jit.tracing.trace.dump:105 of
msgid "enable_fuse_conv_bias_nonlinearity: whether to fuse conv+bias+nonlinearty into one opr."
msgstr "enable_fuse_conv_bias_nonlinearity: 是否将 conv+bias+nonlinearty 融合为一个 opr。"

#: megengine.jit.tracing.trace.dump:107 of
msgid "enable_fuse_conv_bias_with_z: whether to fuse conv_bias with z input for inference on nvidia backend(this optimization pass will result in mismatch of the precision of output of training and inference)"
msgstr "enable_fuse_conv_bias_with_z: 是否将 conv_bias 与 z 融合以在 nvidia 后端进行推理（此优化过程将导致训练和推理的输出精度不匹配）"

#: megengine.jit.tracing.trace.dump:111 of
msgid "enable_fuse_preprocess: whether to fuse astype\\pad_channel\\dimshuffle and etc opr"
msgstr "enable_fuse_preprocess: 是否融合 astype\\pad_channel\\dimshuffle 等 opr"

#~ msgid "基类：:class:`object`"
#~ msgstr "基类：:class:`object`"

#~ msgid "Initialize self.  See help(type(self)) for accurate signature."
#~ msgstr ""

#~ msgid ":obj:`__init__ <megengine.jit.trace.trace.__init__>`\\"
#~ msgstr ":obj:`__init__ <megengine.jit.trace.trace.__init__>`\\"

#~ msgid ""
#~ ":obj:`trace <megengine.jit.trace.trace>`\\ \\(\\*args\\,"
#~ " \\*\\*kwargs\\)"
#~ msgstr ""
#~ ":obj:`trace <megengine.jit.trace.trace>`\\ \\(\\*args\\,"
#~ " \\*\\*kwargs\\)"

#~ msgid "megengine.jit.trace"
#~ msgstr "megengine.jit.trace"

#~ msgid "Methods"
#~ msgstr "方法"

#~ msgid ""
#~ ":obj:`dump <megengine.jit.trace.dump>`\\ \\(file\\, "
#~ "\\*\\[\\, arg\\_names\\, output\\_names\\, ...\\]\\)"
#~ msgstr ""
#~ ":obj:`dump <megengine.jit.trace.dump>`\\ \\(file\\, "
#~ "\\*\\[\\, arg\\_names\\, output\\_names\\, ...\\]\\)"

#~ msgid ":obj:`get_profile <megengine.jit.trace.get_profile>`\\ \\(\\)"
#~ msgstr ":obj:`get_profile <megengine.jit.trace.get_profile>`\\ \\(\\)"

#~ msgid "level for keeping variable names:"
#~ msgstr ""

#~ msgid "0: none of the names are kept"
#~ msgstr ""

#~ msgid "1: (default)keep names of output vars"
#~ msgstr ""

#~ msgid "2: keep names of all (output and internal) vars"
#~ msgstr ""

#~ msgid "using different dump formats."
#~ msgstr ""

#~ msgid "Get profiling result for compiled trace."
#~ msgstr "获取被追溯（trace）函数在编译后运行的性能结果。"

#~ msgid "返回"
#~ msgstr ""

#~ msgid "a json compatible object."
#~ msgstr "一个兼容json的对象。"

