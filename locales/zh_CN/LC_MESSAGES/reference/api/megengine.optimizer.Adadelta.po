#
msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-04-15 19:44+0800\n"
"PO-Revision-Date: 2021-04-20 09:33\n"
"Last-Translator: \n"
"Language-Team: Chinese Simplified\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Generated-By: Babel 2.4.0\n"
"X-Crowdin-File: /[MegEngine.Documentation] main/locales/zh_CN/LC_MESSAGES/reference/api/megengine.optimizer.Adadelta.po\n"
"X-Crowdin-File-ID: 2552\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:2
msgid "megengine.optimizer.Adadelta"
msgstr "megengine.optimizer.Adadelta"

#: megengine.optimizer.adadelta.Adadelta:1 of
msgid "基类：:class:`megengine.optimizer.optimizer.Optimizer`"
msgstr "基类：:class:`megengine.optimizer.optimizer.Optimizer`"

#: megengine.optimizer.adadelta.Adadelta:1 of
msgid "Implements Adadelta algorithm."
msgstr "实现Adadelta算法。"

#: megengine.optimizer.adadelta.Adadelta:3 of
msgid "It has been proposed in `\"ADADELTA: An Adaptive Learning Rate Method\" <https://arxiv.org/abs/1212.5701>`_."
msgstr "这已经在 `\"ADADELTA: An Adaptive Learning Rate Method\" <https://arxiv.org/abs/1212.5701>` _ 中被提出。"

#: megengine.optimizer.adadelta.Adadelta of
msgid "参数"
msgstr ""

#: megengine.optimizer.adadelta.Adadelta:6 of
msgid "iterable of parameters to optimize or dicts defining parameter groups."
msgstr "可迭代对象，可以是一组待优化的参数，或定义几组参数的dict类型。"

#: megengine.optimizer.adadelta.Adadelta:9 of
msgid "coefficient that scales delta before it is applied to the parameters. Default: 1.0"
msgstr "在将delta应用于参数之前缩放比例系数。默认: 1.0"

#: megengine.optimizer.adadelta.Adadelta:12 of
msgid "coefficient used for computing a running average of squared gradients. Default: 0.9"
msgstr "用于计算平方梯度的移动平均值(running average)的系数。默认: 0.9"

#: megengine.optimizer.adadelta.Adadelta:15 of
msgid "term added to the denominator to improve numerical stability. Default: 1e-6"
msgstr "加到分母上以提高数值稳定性的值。默认: 1e-6"

#: megengine.optimizer.adadelta.Adadelta:18 of
msgid "weight decay (L2 penalty). Default: 0"
msgstr "权重衰减(L2惩罚)。默认：0"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:11
msgid "Methods"
msgstr "方法"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`__init__ <megengine.optimizer.Adadelta.__init__>`\\ \\(params\\[\\, lr\\, rho\\, eps\\, weight\\_decay\\]\\)"
msgstr ":obj:`__init__ <megengine.optimizer.Adadelta.__init__>`\\ \\(params\\[\\, lr\\, rho\\, eps\\, weight\\_decay\\]\\)"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid "Initialize self."
msgstr "初始化方法。"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`add_param_group <megengine.optimizer.Adadelta.add_param_group>`\\ \\(param\\_group\\)"
msgstr ":obj:`add_param_group <megengine.optimizer.Adadelta.add_param_group>`\\ \\(param\\_group\\)"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid "Add a param group to ``param_groups`` of the :class:`~megengine.optim.optimizer.Optimizer`."
msgstr "向 :class:`~megengine.optim.optimizer.Optimizer` 的 ``param_groups`` 中添加一组参数。"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`backward <megengine.optimizer.Adadelta.backward>`\\ \\(loss\\)"
msgstr ":obj:`backward <megengine.optimizer.Adadelta.backward>`\\ \\(loss\\)"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`bcast_param <megengine.optimizer.Adadelta.bcast_param>`\\ \\(\\)"
msgstr ":obj:`bcast_param <megengine.optimizer.Adadelta.bcast_param>`\\ \\(\\)"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`clear_grad <megengine.optimizer.Adadelta.clear_grad>`\\ \\(\\)"
msgstr ":obj:`clear_grad <megengine.optimizer.Adadelta.clear_grad>`\\ \\(\\)"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid "Set the grad attribute to None for all parameters."
msgstr "把所有参数的梯度属性设置为 None。"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`load_state_dict <megengine.optimizer.Adadelta.load_state_dict>`\\ \\(state\\)"
msgstr ":obj:`load_state_dict <megengine.optimizer.Adadelta.load_state_dict>`\\ \\(state\\)"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid "Loads the optimizer state."
msgstr "加载优化器状态。"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`state_dict <megengine.optimizer.Adadelta.state_dict>`\\ \\(\\[keep\\_var\\]\\)"
msgstr ":obj:`state_dict <megengine.optimizer.Adadelta.state_dict>`\\ \\(\\[keep\\_var\\]\\)"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid "Export the optimizer state."
msgstr "导出优化器状态。"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`step <megengine.optimizer.Adadelta.step>`\\ \\(\\)"
msgstr ":obj:`step <megengine.optimizer.Adadelta.step>`\\ \\(\\)"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid "Performs a single optimization step."
msgstr "执行单一优化步骤。"

#: ../../source/reference/api/megengine.optimizer.Adadelta.rst:22:<autosummary>:1
msgid ":obj:`zero_grad <megengine.optimizer.Adadelta.zero_grad>`\\ \\(\\)"
msgstr ":obj:`zero_grad <megengine.optimizer.Adadelta.zero_grad>`\\ \\(\\)"
