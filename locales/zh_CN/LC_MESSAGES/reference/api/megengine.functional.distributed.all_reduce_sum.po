msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-04-25 01:18+0000\n"
"PO-Revision-Date: 2023-05-11 13:04\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: Chinese Simplified\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/api/megengine.functional.distributed.all_reduce_sum.po\n"
"X-Crowdin-File-ID: 9081\n"

#: ../../source/reference/api/megengine.functional.distributed.all_reduce_sum.rst:2
msgid "megengine.functional.distributed.all\\_reduce\\_sum"
msgstr "megengine.functional.distributed.all\\_reduce\\_sum"

#: megengine.distributed.functional.all_reduce_sum:1 of
msgid "Reduce tensors with sum operation on each value across the specified group."
msgstr "在指定组中以求和操作来对张量进行规约操作。"

#: megengine.distributed.functional.all_reduce_sum:3 of
msgid "``inp`` tensor must have identical shape in all processes across the group."
msgstr "``inp`` 张量在整个组的所有进程中必须形状相同。"

#: megengine.distributed.functional.all_reduce_sum of
msgid "参数"
msgstr "参数"

#: megengine.distributed.functional.all_reduce_sum:6 of
msgid "tensor to be reduced."
msgstr "需要规约的张量"

#: megengine.distributed.functional.all_reduce_sum of
msgid "关键字参数"
msgstr "关键字参数"

#: megengine.distributed.functional.all_reduce_sum:9 of
msgid "the process group to work on. Default: ``WORLD``. ``WORLD`` group selects all processes available. list of process rank as parameter will create a new group to work on."
msgstr "需要处理的组。默认值：“WORLD”. ``WORLD`` 组包含所有可用的进程。可以以进程序号构建一个列表以创建一个新的组。"

#: megengine.distributed.functional.all_reduce_sum:13 of
msgid "the specific device to execute this operator. Default: ``None`` ``None`` will select the device of ``inp`` to execute. Specially, ``GPU`` device can assign a different stream to execute by adding a number right after a colon following the device name while ``:0`` denotes default stream of GPU, otherwise will use default stream."
msgstr "执行此操作的设备。默认值： ``None``. ``None`` 表示以 ``inp`` 的设备作为执行设备。特别地， ``GPU`` 设备可以通过在设备名后的冒号后面添加一个数字来分配要执行的 cuda 流，而 ``:0`` 表示 GPU 的默认流，不指定流则表示使用默认流。"

#: megengine.distributed.functional.all_reduce_sum of
msgid "返回类型"
msgstr "返回类型"

#: megengine.distributed.functional.all_reduce_sum:20 of
msgid ":py:class:`~megengine.tensor.Tensor`"
msgstr ":py:class:`~megengine.tensor.Tensor`"

#: megengine.distributed.functional.all_reduce_sum of
msgid "返回"
msgstr "返回"

#: megengine.distributed.functional.all_reduce_sum:21 of
msgid "A tensor with sum operation on each value across the group.  The shape of the output tensor must be the same as ``inp``, and the output tensor is going to be bitwise identical in all processes across the group."
msgstr "对组中的的值进行求和操作所得到的张量。输出张量的形状必须与 ``inp`` 相同，并且输出张量在整个组的所有进程中都是完全相同的。"

#: megengine.distributed.functional.all_reduce_sum:21 of
msgid "A tensor with sum operation on each value across the group."
msgstr "在指定组中以求和操作来对张量进行规约操作。"

#: megengine.distributed.functional.all_reduce_sum:23 of
msgid "The shape of the output tensor must be the same as ``inp``, and the output tensor is going to be bitwise identical in all processes across the group."
msgstr "输出张量的形状必须与 inp 相同，并且输出张量在整个组的所有进程中都是完全相同的。"

#: megengine.distributed.functional.all_reduce_sum:27 of
msgid "实际案例"
msgstr "实际案例"

#~ msgid "返回类型"
#~ msgstr "返回类型"

#~ msgid ":py:class:`~megengine.tensor.Tensor`"
#~ msgstr ":py:class:`~megengine.tensor.Tensor`"

#~ msgid "Create all_reduce_sum operator for collective communication."
#~ msgstr "创建用于聚合通信的 all_reduce_sum 算子。"

#~ msgid "communication group."
#~ msgstr "通信组。"

#~ msgid "execution device."
#~ msgstr "执行设备。"

#~ msgid "Reduce tensors across the specified group by sum."
#~ msgstr ""

#~ msgid "Input tensor."
#~ msgstr ""

#~ msgid ""
#~ "The process group to work on. The"
#~ " default group is WORLD which means"
#~ " all processes available. You can use"
#~ " a list of process ranks to "
#~ "create new group to work on it,"
#~ " e.g. [1, 3, 5]."
#~ msgstr ""

#~ msgid ""
#~ "The specific device to execute this "
#~ "operator. None default device means the"
#~ " device of inp will be used. "
#~ "Specify \"gpu0:1\" to execute this "
#~ "operator on diffrent cuda stream, 1 "
#~ "is stream id, and default stream "
#~ "id is 0."
#~ msgstr ""

#~ msgid "Result tensor."
#~ msgstr ""

#~ msgid "A tensor with sum operation on each value across the group."
#~ msgstr "对组中的的值进行求和操作所得到的张量。"

#~ msgid ""
#~ "The shape of the output tensor "
#~ "must be the same as ``inp``, and"
#~ " the output tensor is going to "
#~ "be bitwise identical in all processes"
#~ " across the group."
#~ msgstr "输出张量的形状必须与 ``inp`` 相同，并且输出张量在整个组的所有进程中都是完全相同的。"

#~ msgid "关键字参数"
#~ msgstr "关键字参数"

#~ msgid "Keyword Arguments"
#~ msgstr "关键字参数"

