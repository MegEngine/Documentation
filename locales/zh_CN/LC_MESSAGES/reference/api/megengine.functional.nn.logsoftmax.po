msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-06-03 10:50+0800\n"
"PO-Revision-Date: 2021-08-17 22:47\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: Chinese Simplified\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.4.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /[MegEngine.Documentation] main/locales/zh_CN/LC_MESSAGES/reference/api/megengine.functional.nn.logsoftmax.po\n"
"X-Crowdin-File-ID: 3256\n"

#: ../../source/reference/api/megengine.functional.nn.logsoftmax.rst:2
msgid "megengine.functional.nn.logsoftmax"
msgstr ""

#: megengine.functional.nn.logsoftmax:1 of
msgid "Applies the :math:`\\log(\\text{softmax}(x))` function to an n-dimensional input tensor. The :math:`\\text{logsoftmax}(x)` formulation can be simplified as:"
msgstr "对一个n维的输入张量做 :math:`\\log(\\text{softmax}(x))` 函数 :math:`\\text{logsoftmax}(x)` 的公式可以简化为："

#: megengine.functional.nn.logsoftmax:4 of
msgid "\\text{logsoftmax}(x_{i}) = \\log(\\frac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} )\n\n"
msgstr ""

#: megengine.functional.nn.logsoftmax:7 of
msgid "For numerical stability the implementation follows this transformation:"
msgstr "为了提高数值稳定性，实现根据以下的变换："

#: megengine.functional.nn.logsoftmax:9 of
msgid "\\text{logsoftmax}(x)\n"
"= \\log (\\frac{\\exp (x)}{\\sum_{i}(\\exp (x_{i}))})\n"
"= x - \\log (\\sum_{i}(\\exp (x_{i})))\n"
"= x - \\text{logsumexp}(x)\n\n"
msgstr ""

#: megengine.functional.nn.logsoftmax of
msgid "参数"
msgstr ""

#: megengine.functional.nn.logsoftmax:15 of
msgid "input tensor."
msgstr "输入张量。"

#: megengine.functional.nn.logsoftmax:16 of
msgid "axis along which :math:`\\text{logsoftmax}(x)` will be applied."
msgstr "沿着该维度应用 :math:`\\text{logsoftmax}(x)`。"

#: megengine.functional.nn.logsoftmax:18 of
msgid "Examples:"
msgstr "例如："

#: megengine.functional.nn.logsoftmax:30 of
msgid "Outputs:"
msgstr "输出："

#~ msgid ""
#~ "Applies the :math:`\\log(\\text{softmax}(x))` "
#~ "function to an n-dimensional input "
#~ "tensor. The :math:`\\text{logsoftmax}(x)` "
#~ "formulation can be simplified as:"
#~ msgstr ""

#~ msgid ""
#~ "\\text{logsoftmax}(x_{i}) = \\log(\\frac{\\exp(x_i) "
#~ "}{ \\sum_j \\exp(x_j)} )\n"
#~ "\n"
#~ msgstr ""

#~ msgid ""
#~ "\\text{logsoftmax}(x)\n"
#~ "= \\log (\\frac{\\exp (x)}{\\sum_{i}(\\exp (x_{i}))})\n"
#~ "= x - \\log (\\sum_{i}(\\exp (x_{i})))\n"
#~ "= x - \\text{logsumexp}(x)\n"
#~ "\n"
#~ msgstr ""

#~ msgid "参数"
#~ msgstr ""

#~ msgid "axis along which :math:`\\text{logsoftmax}(x)` will be applied."
#~ msgstr ""

#~ msgid ""
#~ "Applies the :math:`\\log(    ext{softmax}(x))` "
#~ "function to an n-dimensional input "
#~ "tensor. The :math:`   ext{logsoftmax}(x)` "
#~ "formulation can be simplified as:"
#~ msgstr ""

#~ msgid ""
#~ "ext{logsoftmax}(x_{i}) = \\log(\n"
#~ "\n"
#~ msgstr ""

#~ msgid "rac{\\exp(x_i) }{ \\sum_j \\exp(x_j)} )"
#~ msgstr ""

#~ msgid ""
#~ "ext{logsoftmax}(x)\n"
#~ "= \\log (\n"
#~ "\n"
#~ msgstr ""

#~ msgid "rac{\\exp (x)}{\\sum_{i}(\\exp (x_{i}))})"
#~ msgstr ""

#~ msgid "= x - \\log (\\sum_{i}(\\exp (x_{i}))) = x -   ext{logsumexp}(x)"
#~ msgstr ""

#~ msgid "param inp"
#~ msgstr ""

#~ msgid "param axis"
#~ msgstr ""

#~ msgid "axis along which :math:`       ext{logsoftmax}(x)` will be applied."
#~ msgstr ""

