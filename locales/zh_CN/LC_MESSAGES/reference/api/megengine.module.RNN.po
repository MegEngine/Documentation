msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-09-21 10:50+0000\n"
"PO-Revision-Date: 2023-09-21 10:56\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: Chinese Simplified\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/api/megengine.module.RNN.po\n"
"X-Crowdin-File-ID: 9537\n"

#: ../../source/reference/api/megengine.module.RNN.rst:5
msgid "RNN"
msgstr "RNN"

#: megengine.module.rnn.RNN:1 of
msgid "Applies a multi-layer Elman RNN with :math:`\\tanh` or :math:`\\text{ReLU}` non-linearity to an input sequence."
msgstr "对输入序列应用一个多层 Elman RNN, 其中非线性单元采用的 :math:`\\tanh` 或者 :math:`\\text{ReLU}`。"

#: megengine.module.rnn.RNN:5 of
msgid "For each element in the input sequence, each layer computes the following function:"
msgstr "针对输入序列的每一个元素，每一层网络做如下计算："

#: megengine.module.rnn.RNN:7 of
msgid "h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n\n"
msgstr "h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n\n"

#: megengine.module.rnn.RNN:10 of
msgid "where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the previous layer at time `t-1` or the initial hidden state at time `0`. If :attr:`nonlinearity` is ``'relu'``, then :math:`\\text{ReLU}` is used instead of :math:`\\tanh`."
msgstr "其中, :math:`h_t` 是 `t` 时刻的隐藏状态, :math:`x_t` 是 `t` 时刻的输入，而 :math:`h_{(t-1)}` 是 `t-1` 时刻上一层网络的隐藏状态或 `0` 时刻的初始隐藏状态。如果 :attr:`nonlinearity` 为 ``'relu'``，则 \n"
" :math:`\\tanh` 会被 :math:`\\text{ReLU}` 替换。"

#: megengine.module.rnn.RNN of
msgid "参数"
msgstr "参数"

#: megengine.module.rnn.RNN:15 of
msgid "The number of expected features in the input `x`."
msgstr ""

#: megengine.module.rnn.RNN:17 of
msgid "The number of features in the hidden state `h`."
msgstr ""

#: megengine.module.rnn.RNN:19 of
msgid "Number of recurrent layers. E.g., setting ``num_layers=2`` would mean stacking two RNNs together to form a `stacked RNN`, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1."
msgstr ""

#: megengine.module.rnn.RNN:24 of
msgid "The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``."
msgstr ""

#: megengine.module.rnn.RNN:26 of
msgid "If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`. Default: ``True``."
msgstr ""

#: megengine.module.rnn.RNN:29 of
msgid "If ``True``, then the input and output tensors are provided as `(batch, seq, feature)` instead of `(seq, batch, feature)`. Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details.  Default: ``False``."
msgstr ""

#: megengine.module.rnn.RNN:34 of
msgid "If non-zero, introduces a `Dropout` layer on the outputs of each RNN layer except the last layer, with dropout probability equal to :attr:`dropout`. Default: 0."
msgstr ""

#: megengine.module.rnn.RNN:38 of
msgid "If ``True``, becomes a bidirectional RNN. Default: ``False``."
msgstr ""

#: megengine.module.rnn.RNN:63 of
msgid "Shape:"
msgstr "形状："

#: megengine.module.rnn.RNN:57 of
msgid "Inputs: input, h_0"
msgstr "输入: input, h_0"

#: megengine.module.rnn.RNN:43 of
msgid "input: :math:`(L, N, H_{in})` when ``batch_first=False`` or :math:`(N, L, H_{in})`"
msgstr ""

#: megengine.module.rnn.RNN:44 of
msgid "when ``batch_first=True``. Containing the features of the input sequence."
msgstr ""

#: megengine.module.rnn.RNN:46 of
msgid "h_0: :math:`(D * \\text{num\\_layers}, N, H_{out})`. Containing the initial hidden"
msgstr ""

#: megengine.module.rnn.RNN:46 of
msgid "state for each element in the batch. Defaults to zeros if not provided."
msgstr ""

#: megengine.module.rnn.RNN:48 of
msgid "where:"
msgstr "其中："

#: megengine.module.rnn.RNN:50 of
msgid "\\begin{aligned}\n"
"    N ={} & \\text{batch size} \\\\\n"
"    L ={} & \\text{sequence length} \\\\\n"
"    D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n"
"    H_{in} ={} & \\text{input\\_size} \\\\\n"
"    H_{out} ={} & \\text{hidden\\_size}\n"
"\\end{aligned}\n\n"
msgstr "\\begin{aligned}\n"
"    N ={} & \\text{batch size} \\\\\n"
"    L ={} & \\text{sequence length} \\\\\n"
"    D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n"
"    H_{in} ={} & \\text{input\\_size} \\\\\n"
"    H_{out} ={} & \\text{hidden\\_size}\n"
"\\end{aligned}\n\n"

#: megengine.module.rnn.RNN:63 of
msgid "Outputs: output, h_n"
msgstr "输出: output, h_n"

#: megengine.module.rnn.RNN:60 of
msgid "output: :math:`(L, N, D * H_{out})` when ``batch_first=False`` or :math:`(N, L, D * H_{out})` when ``batch_first=True``."
msgstr ""

#: megengine.module.rnn.RNN:61 of
msgid "Containing the output features `(h_t)` from the last layer of the RNN, for each `t`."
msgstr ""

#: megengine.module.rnn.RNN:62 of
msgid "h_n: :math:`(D * \\text{num\\_layers}, N, H_{out})`. Containing the final hidden state for each element in the batch."
msgstr ""

#: megengine.module.rnn.RNN:66 of
msgid "实际案例"
msgstr "实际案例"

#: megengine.module.rnn.RNN:79 of
msgid "Outputs:"
msgstr "输出："

#~ msgid ""
#~ "**input**: tensor of shape :math:`(L, N,"
#~ " H_{in})` when ``batch_first=False`` or "
#~ ":math:`(N, L, H_{in})` when "
#~ "``batch_first=True`` containing the features "
#~ "of the input sequence.  The input "
#~ "can also be a packed variable "
#~ "length sequence. See "
#~ ":func:`torch.nn.utils.rnn.pack_padded_sequence` or "
#~ ":func:`torch.nn.utils.rnn.pack_sequence` for details."
#~ msgstr ""
#~ "**input**: 包含输入序列特征的 tensor, 当 "
#~ "``batch_first=False`` 时，其 shape 为 :math:`(L,"
#~ " N, H_{in})`, 反之，其 shape 为 :math:`(N,"
#~ " L, H_{in})`. 输入也可以是一个打包过的变长序列。具体参见 "
#~ ":func:`torch.nn.utils.rnn.pack_padded_sequence` 或 "
#~ ":func:`torch.nn.utils.rnn.pack_sequence`."

#~ msgid ""
#~ "**h_0**: tensor of shape :math:`(D * "
#~ "\\text{num\\_layers}, N, H_{out})` containing "
#~ "the initial hidden state for each "
#~ "element in the batch. Defaults to "
#~ "zeros if not provided."
#~ msgstr ""
#~ "**h_0**: shape 为 :math:`(D * "
#~ "\\text{num\\_layers}, N, H_{out})` 的tensor, "
#~ "包含当前batch中每一个元素的隐藏层状态的初始化值。默认全零。"

#~ msgid ""
#~ "**output**: tensor of shape :math:`(L, "
#~ "N, D * H_{out})` when "
#~ "``batch_first=False`` or :math:`(N, L, D "
#~ "* H_{out})` when ``batch_first=True`` "
#~ "containing the output features `(h_t)` "
#~ "from the last layer of the RNN,"
#~ " for each `t`. If a "
#~ ":class:`torch.nn.utils.rnn.PackedSequence` has been "
#~ "given as the input, the output "
#~ "will also be a packed sequence."
#~ msgstr ""
#~ "**output**: 包含每一个 `t` 取值下的 RNN 末层的输出特征"
#~ " `(h_t)`, 当 ``batch_first=False`` 时，其 shape"
#~ " 为 :math:`(L, N, D * H_{out})`, "
#~ "反之，shape 为 :math:`(N, L, D * "
#~ "H_{out})`。如果输入是 :class:`torch.nn.utils.rnn.PackedSequence`, "
#~ "则输出也变成一个打包后的序列。"

