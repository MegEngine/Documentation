msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-09-21 10:50+0000\n"
"PO-Revision-Date: 2023-09-27 07:18\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: Chinese Simplified\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.11.0\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/api/megengine.module.RNN.po\n"
"X-Crowdin-File-ID: 9537\n"

#: ../../source/reference/api/megengine.module.RNN.rst:5
msgid "RNN"
msgstr "RNN"

#: megengine.module.rnn.RNN:1 of
msgid "Applies a multi-layer Elman RNN with :math:`\\tanh` or :math:`\\text{ReLU}` non-linearity to an input sequence."
msgstr "对输入序列应用一个多层 Elman RNN, 其中非线性单元采用的 :math:`\\tanh` 或者 :math:`\\text{ReLU}`。"

#: megengine.module.rnn.RNN:5 of
msgid "For each element in the input sequence, each layer computes the following function:"
msgstr "针对输入序列的每一个元素，每一层网络做如下计算："

#: megengine.module.rnn.RNN:7 of
msgid "h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n\n"
msgstr "h_t = \\tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})\n\n"

#: megengine.module.rnn.RNN:10 of
msgid "where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input at time `t`, and :math:`h_{(t-1)}` is the hidden state of the previous layer at time `t-1` or the initial hidden state at time `0`. If :attr:`nonlinearity` is ``'relu'``, then :math:`\\text{ReLU}` is used instead of :math:`\\tanh`."
msgstr "其中, :math:`h_t` 是 `t` 时刻的隐藏状态, :math:`x_t` 是 `t` 时刻的输入，而 :math:`h_{(t-1)}` 是 `t-1` 时刻上一层网络的隐藏状态或 `0` 时刻的初始隐藏状态。如果 :attr:`nonlinearity` 为 ``'relu'``，则 \n"
" :math:`\\tanh` 会被 :math:`\\text{ReLU}` 替换。"

#: megengine.module.rnn.RNN of
msgid "参数"
msgstr "参数"

#: megengine.module.rnn.RNN:15 of
msgid "The number of expected features in the input `x`."
msgstr "输入 `x` 中特征的数量。"

#: megengine.module.rnn.RNN:17 of
msgid "The number of features in the hidden state `h`."
msgstr "隐藏状态 `h` 中的特征数量。"

#: megengine.module.rnn.RNN:19 of
msgid "Number of recurrent layers. E.g., setting ``num_layers=2`` would mean stacking two RNNs together to form a `stacked RNN`, with the second RNN taking in outputs of the first RNN and computing the final results. Default: 1."
msgstr "循环层的数量。比如设置 ``num_layers=2`` 将会叠加两层循环神经网络，其中第二层的循环神经网络以第一层的循环神经网络的输出作为输入并计算最终的结果。默认值：1。"

#: megengine.module.rnn.RNN:24 of
msgid "The non-linearity to use. Can be either ``'tanh'`` or ``'relu'``. Default: ``'tanh'``."
msgstr "非线性层。可以是 ``'tanh'`` 或者 ``'relu'``。默认值：``'tanh'``。"

#: megengine.module.rnn.RNN:26 of
msgid "If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`. Default: ``True``."
msgstr "如果为``False``，则这一层不使用偏置权值 `b_ih` 和 `b_hh`。默认值：``True``。"

#: megengine.module.rnn.RNN:29 of
msgid "If ``True``, then the input and output tensors are provided as `(batch, seq, feature)` instead of `(seq, batch, feature)`. Note that this does not apply to hidden or cell states. See the Inputs/Outputs sections below for details.  Default: ``False``."
msgstr "如果 ``True``，则输入和输出张量的形状将是 `(batch, seq, feature)`，而不是 `(seq, batch, feature)`。需要注意的是，这不适用于 hidden 或 cell state。更多详细信息，请参阅下面的输入/输出部分。默认值：``False ``。"

#: megengine.module.rnn.RNN:34 of
msgid "If non-zero, introduces a `Dropout` layer on the outputs of each RNN layer except the last layer, with dropout probability equal to :attr:`dropout`. Default: 0."
msgstr "如果不是零，则在除最后一层之外的每个 RNN 层的输出上引入 `Dropout` 层，dropout rate 通过 :attr:`dropout` 设置。默认值：0。"

#: megengine.module.rnn.RNN:38 of
msgid "If ``True``, becomes a bidirectional RNN. Default: ``False``."
msgstr "如果 ``True``，则变为双向 RNN。默认值：``False ``。"

#: megengine.module.rnn.RNN:63 of
msgid "Shape:"
msgstr "形状："

#: megengine.module.rnn.RNN:57 of
msgid "Inputs: input, h_0"
msgstr "输入: input, h_0"

#: megengine.module.rnn.RNN:43 of
msgid "input: :math:`(L, N, H_{in})` when ``batch_first=False`` or :math:`(N, L, H_{in})`"
msgstr "输入：如果 ``batch_first=False``，则为 :math:`(L, N, H_{in})`，否则 :math:`(N, L, H_{in})`。"

#: megengine.module.rnn.RNN:44 of
msgid "when ``batch_first=True``. Containing the features of the input sequence."
msgstr ""

#: megengine.module.rnn.RNN:46 of
msgid "h_0: :math:`(D * \\text{num\\_layers}, N, H_{out})`. Containing the initial hidden"
msgstr ""

#: megengine.module.rnn.RNN:46 of
msgid "state for each element in the batch. Defaults to zeros if not provided."
msgstr ""

#: megengine.module.rnn.RNN:48 of
msgid "where:"
msgstr "其中："

#: megengine.module.rnn.RNN:50 of
msgid "\\begin{aligned}\n"
"    N ={} & \\text{batch size} \\\\\n"
"    L ={} & \\text{sequence length} \\\\\n"
"    D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n"
"    H_{in} ={} & \\text{input\\_size} \\\\\n"
"    H_{out} ={} & \\text{hidden\\_size}\n"
"\\end{aligned}\n\n"
msgstr "\\begin{aligned}\n"
"    N ={} & \\text{batch size} \\\\\n"
"    L ={} & \\text{sequence length} \\\\\n"
"    D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n"
"    H_{in} ={} & \\text{input\\_size} \\\\\n"
"    H_{out} ={} & \\text{hidden\\_size}\n"
"\\end{aligned}\n\n"

#: megengine.module.rnn.RNN:63 of
msgid "Outputs: output, h_n"
msgstr "输出: output, h_n"

#: megengine.module.rnn.RNN:60 of
msgid "output: :math:`(L, N, D * H_{out})` when ``batch_first=False`` or :math:`(N, L, D * H_{out})` when ``batch_first=True``."
msgstr ""

#: megengine.module.rnn.RNN:61 of
msgid "Containing the output features `(h_t)` from the last layer of the RNN, for each `t`."
msgstr ""

#: megengine.module.rnn.RNN:62 of
msgid "h_n: :math:`(D * \\text{num\\_layers}, N, H_{out})`. Containing the final hidden state for each element in the batch."
msgstr ""

#: megengine.module.rnn.RNN:66 of
msgid "实际案例"
msgstr "实际案例"

#: megengine.module.rnn.RNN:79 of
msgid "Outputs:"
msgstr "输出："

#~ msgid ""
#~ "**input**: tensor of shape :math:`(L, N,"
#~ " H_{in})` when ``batch_first=False`` or "
#~ ":math:`(N, L, H_{in})` when "
#~ "``batch_first=True`` containing the features "
#~ "of the input sequence.  The input "
#~ "can also be a packed variable "
#~ "length sequence. See "
#~ ":func:`torch.nn.utils.rnn.pack_padded_sequence` or "
#~ ":func:`torch.nn.utils.rnn.pack_sequence` for details."
#~ msgstr ""
#~ "**input**: 包含输入序列特征的 tensor, 当 "
#~ "``batch_first=False`` 时，其 shape 为 :math:`(L,"
#~ " N, H_{in})`, 反之，其 shape 为 :math:`(N,"
#~ " L, H_{in})`. 输入也可以是一个打包过的变长序列。具体参见 "
#~ ":func:`torch.nn.utils.rnn.pack_padded_sequence` 或 "
#~ ":func:`torch.nn.utils.rnn.pack_sequence`."

#~ msgid ""
#~ "**h_0**: tensor of shape :math:`(D * "
#~ "\\text{num\\_layers}, N, H_{out})` containing "
#~ "the initial hidden state for each "
#~ "element in the batch. Defaults to "
#~ "zeros if not provided."
#~ msgstr ""
#~ "**h_0**: shape 为 :math:`(D * "
#~ "\\text{num\\_layers}, N, H_{out})` 的tensor, "
#~ "包含当前batch中每一个元素的隐藏层状态的初始化值。默认全零。"

#~ msgid ""
#~ "**output**: tensor of shape :math:`(L, "
#~ "N, D * H_{out})` when "
#~ "``batch_first=False`` or :math:`(N, L, D "
#~ "* H_{out})` when ``batch_first=True`` "
#~ "containing the output features `(h_t)` "
#~ "from the last layer of the RNN,"
#~ " for each `t`. If a "
#~ ":class:`torch.nn.utils.rnn.PackedSequence` has been "
#~ "given as the input, the output "
#~ "will also be a packed sequence."
#~ msgstr ""
#~ "**output**: 包含每一个 `t` 取值下的 RNN 末层的输出特征"
#~ " `(h_t)`, 当 ``batch_first=False`` 时，其 shape"
#~ " 为 :math:`(L, N, D * H_{out})`, "
#~ "反之，shape 为 :math:`(N, L, D * "
#~ "H_{out})`。如果输入是 :class:`torch.nn.utils.rnn.PackedSequence`, "
#~ "则输出也变成一个打包后的序列。"

