msgid ""
msgstr ""
"Project-Id-Version: megengine\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-02-14 16:12+0800\n"
"PO-Revision-Date: 2023-04-21 09:29\n"
"Last-Translator: \n"
"Language: zh_CN\n"
"Language-Team: Chinese Simplified\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"
"X-Crowdin-Project: megengine\n"
"X-Crowdin-Project-ID: 450980\n"
"X-Crowdin-Language: zh-CN\n"
"X-Crowdin-File: /dev/locales/zh_CN/LC_MESSAGES/reference/api/megengine.optimizer.Optimizer.po\n"
"X-Crowdin-File-ID: 9655\n"

#: ../../source/reference/api/megengine.optimizer.Optimizer.rst:5
msgid "Optimizer"
msgstr ""

#: megengine.optimizer.optimizer.Optimizer:1 of
msgid "Base class for all optimizers."
msgstr "所有优化器的基类。"

#: megengine.optimizer.optimizer.Optimizer
#: megengine.optimizer.optimizer.Optimizer.add_param_group
#: megengine.optimizer.optimizer.Optimizer.load_state_dict of
msgid "参数"
msgstr ""

#: megengine.optimizer.optimizer.Optimizer:4 of
msgid "specifies what Tensors should be optimized."
msgstr "指定应该优化哪些张量。"

#: megengine.optimizer.optimizer.Optimizer:6 of
msgid "a dict of default parameters of Optimizer, like learning rate or momentum."
msgstr "一个含有优化器默认参数的dict，如含有学习率(learning rate)和动量(momentum)。"

#: megengine.optimizer.optimizer.Optimizer.add_param_group:1 of
msgid "Add a param group to ``param_groups`` of the :class:`~megengine.optim.optimizer.Optimizer`."
msgstr "向 :class:`~megengine.optim.optimizer.Optimizer` 的 ``param_groups`` 中添加一组参数。"

#: megengine.optimizer.optimizer.Optimizer.add_param_group:3 of
msgid "This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the :class:`~megengine.optim.optimizer.Optimizer` as training progresses."
msgstr "该方法可以在微调(fine-tuning)预训练网络时发挥作用，在训练过程中，冻结层通过此方法加入到 :class:`~megengine.optim.optimizer.Optimizer` 中变为可训练层。"

#: megengine.optimizer.optimizer.Optimizer.add_param_group:7 of
msgid "specifies what tensors should be optimized along with group."
msgstr "指定了应与参数组一起进行优化的张量。"

#: megengine.optimizer.optimizer.Optimizer.clear_grad:1 of
msgid "Set the grad attribute to None for all parameters."
msgstr "把所有参数的梯度属性设置为 None。"

#: megengine.optimizer.optimizer.Optimizer.load_state_dict:1 of
msgid "Loads the optimizer state."
msgstr "加载优化器状态。"

#: megengine.optimizer.optimizer.Optimizer.load_state_dict:4 of
msgid "optimizer state. Should be an object returned from a call to :meth:`state_dict`."
msgstr "优化器状态。应为调用 :meth:`state_dict` 返回的对象。"

#: megengine.optimizer.optimizer.Optimizer.state_dict:1 of
msgid "Export the optimizer state."
msgstr "导出优化器状态。"

#: megengine.optimizer.optimizer.Optimizer.state_dict of
msgid "返回类型"
msgstr ""

#: megengine.optimizer.optimizer.Optimizer.state_dict:3 of
msgid ":py:class:`~typing.Dict`"
msgstr ""

#: megengine.optimizer.optimizer.Optimizer.state_dict of
msgid "返回"
msgstr ""

#: megengine.optimizer.optimizer.Optimizer.state_dict:4 of
msgid "optimizer state. Can be loaded by :meth:`load_state_dict`."
msgstr "优化器状态。可通过 :meth:`load_state_dict` 来加载。"

#: megengine.optimizer.optimizer.Optimizer.step:1 of
msgid "Performs a single optimization step."
msgstr "执行单一优化步骤。"

#: megengine.optimizer.optimizer.Optimizer.zero_grad:1 of
msgid "use clear_grad instead"
msgstr "用 clear_grad 替代"

#~ msgid "基类：:class:`object`"
#~ msgstr "基类：:class:`object`"

#~ msgid ""
#~ ":obj:`__init__ <megengine.optimizer.Optimizer.__init__>`\\ "
#~ "\\(params\\, defaults\\)"
#~ msgstr ""
#~ ":obj:`__init__ <megengine.optimizer.Optimizer.__init__>`\\ "
#~ "\\(params\\, defaults\\)"

#~ msgid "Initialize self."
#~ msgstr "初始化方法。"

#~ msgid "megengine.optimizer.Optimizer"
#~ msgstr "megengine.optimizer.Optimizer"

#~ msgid "Methods"
#~ msgstr "方法"

#~ msgid ""
#~ ":obj:`add_param_group "
#~ "<megengine.optimizer.Optimizer.add_param_group>`\\ "
#~ "\\(param\\_group\\)"
#~ msgstr ""
#~ ":obj:`add_param_group "
#~ "<megengine.optimizer.Optimizer.add_param_group>`\\ "
#~ "\\(param\\_group\\)"

#~ msgid ":obj:`backward <megengine.optimizer.Optimizer.backward>`\\ \\(loss\\)"
#~ msgstr ":obj:`backward <megengine.optimizer.Optimizer.backward>`\\ \\(loss\\)"

#~ msgid ":obj:`bcast_param <megengine.optimizer.Optimizer.bcast_param>`\\ \\(\\)"
#~ msgstr ":obj:`bcast_param <megengine.optimizer.Optimizer.bcast_param>`\\ \\(\\)"

#~ msgid ":obj:`clear_grad <megengine.optimizer.Optimizer.clear_grad>`\\ \\(\\)"
#~ msgstr ":obj:`clear_grad <megengine.optimizer.Optimizer.clear_grad>`\\ \\(\\)"

#~ msgid ""
#~ ":obj:`load_state_dict "
#~ "<megengine.optimizer.Optimizer.load_state_dict>`\\ \\(state\\)"
#~ msgstr ""
#~ ":obj:`load_state_dict "
#~ "<megengine.optimizer.Optimizer.load_state_dict>`\\ \\(state\\)"

#~ msgid ""
#~ ":obj:`state_dict <megengine.optimizer.Optimizer.state_dict>`\\"
#~ " \\(\\[keep\\_var\\]\\)"
#~ msgstr ""
#~ ":obj:`state_dict <megengine.optimizer.Optimizer.state_dict>`\\"
#~ " \\(\\[keep\\_var\\]\\)"

#~ msgid ":obj:`step <megengine.optimizer.Optimizer.step>`\\ \\(\\)"
#~ msgstr ":obj:`step <megengine.optimizer.Optimizer.step>`\\ \\(\\)"

#~ msgid ":obj:`zero_grad <megengine.optimizer.Optimizer.zero_grad>`\\ \\(\\)"
#~ msgstr ":obj:`zero_grad <megengine.optimizer.Optimizer.zero_grad>`\\ \\(\\)"

